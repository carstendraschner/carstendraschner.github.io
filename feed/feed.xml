<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="pretty-atom-feed.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>Blog Title</title>
  <subtitle>This is a longer description about your blog.</subtitle>
  <link href="https://example.com/feed/feed.xml" rel="self" />
  <link href="https://example.com/" />
  <updated>2024-12-27T00:00:00Z</updated>
  <id>https://example.com/</id>
  <author>
    <name>Your Name</name>
  </author>
  <entry>
    <title>New DE/EU Open Source LLM ğŸ‡ªğŸ‡º Teuken 7B, Now Truly Open Source?</title>
    <link href="https://example.com/blog/241127_Teuken_Review/" />
    <updated>2024-12-27T00:00:00Z</updated>
    <id>https://example.com/blog/241127_Teuken_Review/</id>
    <content type="html">&lt;p&gt;New Model out of Open-GPT-X developed within Germany from European Perspective&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/u966D37VBY-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/u966D37VBY-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/u966D37VBY-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;749&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New German OS LLM&lt;/li&gt;
&lt;li&gt;7B, Transperant Docs&lt;/li&gt;
&lt;li&gt;Problems in Alignment?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;short-facts&quot;&gt;Short Facts&lt;/h2&gt;
&lt;p&gt;ğŸ‡ªğŸ‡º European language focus
ğŸ¤– 7B parameters
ğŸ”— Very open Apache 2.0 license
ğŸ› ï¸ Instruction Fine-tuned
ğŸ“Š Not outperforming in Benchmarks but also within normal distribution (for ğŸ‡¬ğŸ‡§)
ğŸ‘¶ğŸ¼ 4k max context
ğŸ’£ (EDIT) Alignment Discussion see here: &lt;a href=&quot;https://lnkd.in/eseXDMMS&quot;&gt;https://lnkd.in/eseXDMMS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My former colleagues Mehdi Ali (roommate within our time in Smart Data Analytics at Rheinische Friedrich-Wilhelms-UniversitÃ¤t Bonn of Jens Lehmann) and Stefan Wrobel (one of my Ph.D. supervisors Rheinische Friedrich-Wilhelms-UniversitÃ¤t Bonn) and their teams have released an LLM developed in Europe within OpenGPT-X &amp;amp; Fraunhofer IAIS. This has been developed with a focus on European languages. I&#39;m excited to try it out right away and see the actual performance! They announced their own Leaderboard and the Model in somewhere in between other models of same size: &lt;a href=&quot;https://lnkd.in/eTgv8bjV&quot;&gt;https://lnkd.in/eTgv8bjV&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;my-take&quot;&gt;My Take ğŸ¤—&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I have high hopes for a better documentation of the development process and I am curious if this model can be called truly open source and not just open weight.&lt;/li&gt;
&lt;li&gt;I look forward to further European and German initiatives that also pursue (Gen)AI development here in ğŸ‡ªğŸ‡ºâ¤ï¸&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions-at-mehdi-ali-michael-fromm-max-luebbering-phd-and-all-your-contributors&quot;&gt;My Questions (at Mehdi Ali, Michael Fromm, Max LÃ¼bbering, PhD and all your contributors):&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Is anyone capable to entirely reproduce the model from the documentation?&lt;/li&gt;
&lt;li&gt;What do you expect from Arena Elo Scores?&lt;/li&gt;
&lt;li&gt;In which tasks would you recommend usage of your model over other models from Mistral AI, Meta, Google, Microsoft, Alibaba Cloud like Mistral7B, LLama3.18B, Gemma, Phi, Qwen...&lt;/li&gt;
&lt;li&gt;Will we see truly big LLMs in size of 50-400B Parameter that can compete with current top notch LLMs from your side?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We at Comma Soft AG provide with Alan.de a European and German Solution to use GenAI in a highly performant, safe and trusted environment. If you like to see more of our recent R&amp;amp;D, check my recent posts and reach out to me for more idea exchange ğŸ˜Š&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>We&#39;re Dealing with the Butterfly Effect in LLM Creation Pipelines ğŸ¦‹ğŸ¤–</title>
    <link href="https://example.com/blog/241120_were_dealing_with_the_butterfly_effect_in_llm_creation_pipelines/" />
    <updated>2024-11-20T00:00:00Z</updated>
    <id>https://example.com/blog/241120_were_dealing_with_the_butterfly_effect_in_llm_creation_pipelines/</id>
    <content type="html">&lt;p&gt;When we develop novel LLMs, AI-Agents and GenAI Pipelines for Alan.de or within our various other GenAI projects, we&#39;re continuously learning about the Butterfly Effect in GenAI creation pipelines and how to mitigate this problem. ğŸ‘¨ğŸ¼â€ğŸ’»
ğŸ¤¯ Every change can have a huge impact on the entire pipeline that creates and executes models&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/ODUjemRpOm-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/ODUjemRpOm-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/ODUjemRpOm-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Butterfly Effect can significantly impact LLM creation pipelines.&lt;/li&gt;
&lt;li&gt;Small changes in preprocessing or generation configs can have large ripple effects.&lt;/li&gt;
&lt;li&gt;Constantly evaluating trade-offs and staying up-to-date with new models is crucial.&lt;/li&gt;
&lt;li&gt;Strategies to mitigate the Butterfly Effect are essential for optimal performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-butterfly-effect-in-action&quot;&gt;The Butterfly Effect in action:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“ƒ &lt;strong&gt;Example 1:&lt;/strong&gt; Preprocessing differences in raw-document data extraction can result in different extracted text, facts, training and benchmarking data, and ultimately, different model performance and benchmark results.&lt;/li&gt;
&lt;li&gt;ğŸ“Š &lt;strong&gt;Example 2:&lt;/strong&gt; Even a slight change in the generation config (e.g. top_p) of a Benchmarking-Data generating AI Agent can have a ripple effect on the entire pipeline to the finally selected best LLM.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-challenge&quot;&gt;The Challenge:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ‘©ğŸ»â€ğŸ”¬ With new models and agents (e.g. LLM-as-Judge) becoming available every day, we need to be prepared to exchange components frequently to stay up-to-date and ensure optimal performance and reliability of our pipeline&lt;/li&gt;
&lt;li&gt;âš–ï¸ This means constantly evaluating the trade-offs between performance, reliability, and interpretability, and making informed decisions about when to update or replace components.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-takes&quot;&gt;My Takes:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§ Be aware of the Butterfly Effect in your LLM creation pipelines and take steps to mitigate its impact.&lt;/li&gt;
&lt;li&gt;ğŸ‘¨ğŸ¼â€ğŸ“ Stay up-to-date with the latest developments (insane task) in the field and be prepared to adapt and evolve your solutions accordingly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions&quot;&gt;My Questions:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¦‹ How do you handle the Butterfly Effect in your LLM creation pipelines?&lt;/li&gt;
&lt;li&gt;ğŸ—ï¸ What strategies do you use to stay up-to-date with the latest developments in the field and ensure optimal performance?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In recent and especially upcoming posts I will address how we Comma Soft AG handle this challenge. If you like to see more of the details please leave me a comment what you think and which questions and ideas you have ğŸ’¬â¤ï¸&lt;/p&gt;
&lt;p&gt;#generativeai #artificialintelligence #llm #machinelearning #alan&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>New Official OSI &quot;Open Source AI definition&quot; attacks Meta&#39;s LLAMA as &quot;Open Washing&quot;</title>
    <link href="https://example.com/blog/241113_new_official_osi_open_source_ai_definition_attacks_metas_llama_as_open_washing/" />
    <updated>2024-11-13T00:00:00Z</updated>
    <id>https://example.com/blog/241113_new_official_osi_open_source_ai_definition_attacks_metas_llama_as_open_washing/</id>
    <content type="html">&lt;p&gt;We getting closer what should be considered being open source in GenAI and not only open weight.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/MZY7DxFWA2-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/MZY7DxFWA2-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/MZY7DxFWA2-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ğŸ“&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official OSI definition of Open Source AI available.&lt;/li&gt;
&lt;li&gt;Meta doesn&#39;t like it ğŸ™…â€â™‚ï¸.&lt;/li&gt;
&lt;li&gt;State-of-the-art (SOTA) models lack being truly Open Source ğŸ¤”.&lt;/li&gt;
&lt;li&gt;&amp;quot;Open Washing&amp;quot; Problem of Meta and others?!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;osi-definition&quot;&gt;OSI Definition ğŸ“œ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Publicly accessible training data ğŸ“Š.&lt;/li&gt;
&lt;li&gt;Publicly accessible code for creation ğŸ’».&lt;/li&gt;
&lt;li&gt;Transparent model weights âš–ï¸.&lt;/li&gt;
&lt;li&gt;Permissive licensing for usage and modification ğŸ“.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-take&quot;&gt;My Take ğŸ¤”&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I mostly agree with the definition of Open Source Initiative (OSI) Open Source AI ğŸ‘.&lt;/li&gt;
&lt;li&gt;I hope more SOTA models like LLAMA of Meta would follow this definition when claiming they are Open Source ğŸ¤.&lt;/li&gt;
&lt;li&gt;There is Open Washing out there, either in title (like OpenAI) or in claiming models are open source but not reproducible (training data and sampling and creation pipeline) ğŸš«.&lt;/li&gt;
&lt;li&gt;I still appreciate that more and more non-fully open source models are available and are at least Open Weight SOTA GenAI models.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;further-reading&quot;&gt;Further Reading ğŸ“š&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Problems with Llama &amp;quot;Open Source&amp;quot; License: &lt;a href=&quot;https://lnkd.in/dtStQSdn&quot;&gt;https://lnkd.in/dtStQSdn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;What &amp;quot;Open&amp;quot; Should Truly Mean: &lt;a href=&quot;https://lnkd.in/e7vxhzKi&quot;&gt;https://lnkd.in/e7vxhzKi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OSI Definition: &lt;a href=&quot;https://lnkd.in/ePtGNnvh&quot;&gt;https://lnkd.in/ePtGNnvh&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you â¤ï¸ this content, leave me a thumb up ğŸ‘, and please share your thoughts in the comments ğŸ’¬&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai #opensource #meta #llama&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>The Uncanny Valley Phenomenon in GenAI Face Synthesis</title>
    <link href="https://example.com/blog/241105_the_uncanny_valley_phenomenon_in_genai_face_synthesis/" />
    <updated>2024-11-05T00:00:00Z</updated>
    <id>https://example.com/blog/241105_the_uncanny_valley_phenomenon_in_genai_face_synthesis/</id>
    <content type="html">&lt;p&gt;GenAI hits Uncanny Valley Problems as we have seen in Animation and Computer Games&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/MFdV8_8zRS-946.avif 946w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/MFdV8_8zRS-946.webp 946w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/MFdV8_8zRS-946.png&quot; alt=&quot;Image 1&quot; width=&quot;946&quot; height=&quot;870&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ğŸ“&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official OSI definition of Open Source AI available.&lt;/li&gt;
&lt;li&gt;Meta doesn&#39;t like it ğŸ™…â€â™‚ï¸.&lt;/li&gt;
&lt;li&gt;State-of-the-art (SOTA) models lack being truly Open Source ğŸ¤”.&lt;/li&gt;
&lt;li&gt;&amp;quot;Open Washing&amp;quot; Problem of Meta and others?!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-is-the-uncanny-valley&quot;&gt;What Is The Uncanny Valley?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The uncanny valley is a phenomenon where human-like objects or characters that are almost, but not quite, indistinguishable from real humans can evoke a sense of eeriness or discomfort. ğŸ¤–&lt;/li&gt;
&lt;li&gt;This concept is particularly relevant in the context of generative AI video synthesis of emotional human faces. ğŸ“¹&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-challenge-of-recreating-lifelike-faces&quot;&gt;The Challenge of Recreating Lifelike Faces&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Creating AI-generated faces that are both realistic and emotionally expressive is a significant challenge. ğŸ¤”&lt;/li&gt;
&lt;li&gt;Small imperfections in facial expressions, movements, or emotional nuances can make the synthesized faces appear strange or creepy to viewers. ğŸ‘»&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-impact-on-emotional-intelligence&quot;&gt;The Impact on Emotional Intelligence&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The uncanny valley phenomenon can have a significant impact on the emotional intelligence of AI systems. ğŸ¤–&lt;/li&gt;
&lt;li&gt;If AI-generated faces are not convincingly realistic, they may not be able to evoke the desired emotional response from humans. ğŸ¤”&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-do-you-think&quot;&gt;What Do You Think?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Can you think of any potential solutions to overcome the uncanny valley phenomenon in generative AI (face synthesis)? ğŸ’¡&lt;/li&gt;
&lt;li&gt;Do you believe that the uncanny valley is a significant challenge that needs to be addressed in the development of emotionally intelligent AI systems? ğŸ¤”&lt;/li&gt;
&lt;li&gt;Share your thoughts and ideas in the comments! ğŸ’¬&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;#genai #deeptech #artificialintelligence #uncannyvalley&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>A GenAI Solution/Tweak to Rescue ARD tagesschau webpage?!</title>
    <link href="https://example.com/blog/241025_a_genai_solution_tweak_to_rescue_ard_tagesschau_webpage/" />
    <updated>2024-10-25T00:00:00Z</updated>
    <id>https://example.com/blog/241025_a_genai_solution_tweak_to_rescue_ard_tagesschau_webpage/</id>
    <content type="html">&lt;p&gt;Brainstorming how old regulations meet new GenAI opportunities.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/O_cWA3fM8t-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/O_cWA3fM8t-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/O_cWA3fM8t-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ğŸ“&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debate over new regulations restricting text content of public broadcasters online.&lt;/li&gt;
&lt;li&gt;Reform could impact news portals like tagesschau.de by limiting text content to only that which accompanies broadcasts.&lt;/li&gt;
&lt;li&gt;GenAI could potentially auto-generate videos from text content to comply with regulations.&lt;/li&gt;
&lt;li&gt;Questions about the impact and regulation of GenAI in public broadcasting contexts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am wondering if my proposed solution would contradict the possible upcoming regulations (see below) ğŸ¤”.&lt;/li&gt;
&lt;li&gt;I might be biased as tagesschau.de is for me one good source of news with a mix of text and video while being free of ads ğŸ“°(IMHO).&lt;/li&gt;
&lt;li&gt;I am writing this as only one example where old regulations might clash with or ignore recent GenAI developments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Current Debate:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More or less every household needs to pay ~18â‚¬ monthly for public broadcast ğŸ’¶.&lt;/li&gt;
&lt;li&gt;State premiers are discussing a reform that would significantly restrict the text content of public broadcasters like ARD and ZDF online ğŸ“„.&lt;/li&gt;
&lt;li&gt;The draft reform mandates that only texts accompanying broadcasts are permitted, meaning text content can only be published if it has been previously covered in a TV broadcast ğŸ“º.&lt;/li&gt;
&lt;li&gt;This change would greatly impact the speed and diversity of reporting, particularly for news portals like tagesschau.de, they say ğŸš«.&lt;/li&gt;
&lt;li&gt;Private publishers, viewing this as a competitive advantage, support the reform, while public broadcaster representatives warn of negative effects on media diversity and information provision ğŸ¢.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;My GenAI Perspective:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What would happen if these platforms autogenerate videos on some digital video stream platform based on the text content they propose? ğŸ¤–.&lt;/li&gt;
&lt;li&gt;We have seen such approaches of text-to-video generation or speech synthesis ğŸ“.&lt;/li&gt;
&lt;li&gt;Maybe with a digital clone of some professional or artificial speaker (who needs to allow this for sure and should get paid for giving away the digital twin) ğŸ—£ï¸.&lt;/li&gt;
&lt;li&gt;Currently we face several conflicts of old media and GenAI but this is more between public broadcast and private publishers âš–ï¸.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do you see it? ğŸ¤·.&lt;/li&gt;
&lt;li&gt;Do you think GenAI content would solve their issue? ğŸ¤”.&lt;/li&gt;
&lt;li&gt;How is it regulated within your country if public broadcast can write articles? ğŸŒ.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Link to ğŸ‡©ğŸ‡ª Tagesschau article: &lt;a href=&quot;https://lnkd.in/dkx_RZun&quot;&gt;https://lnkd.in/dkx_RZun&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#Rundfunkbeitrag #genai #gez #presse #artificialintelligence&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>We Cannot Waste Time and Resources through Regenerating GenAI Creations! GenAI Control is Key for Productivity!</title>
    <link href="https://example.com/blog/241016_we_cannot_waste_time_and_resources_through_regenerating_genai_creations_genai_control_is_key_for_productivity/" />
    <updated>2024-10-16T00:00:00Z</updated>
    <id>https://example.com/blog/241016_we_cannot_waste_time_and_resources_through_regenerating_genai_creations_genai_control_is_key_for_productivity/</id>
    <content type="html">&lt;p&gt;We will see more and more precise adjustment options in GenAI Tooling&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/DGwfP2s1_T-664.avif 664w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/DGwfP2s1_T-664.webp 664w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/DGwfP2s1_T-664.png&quot; alt=&quot;Image 1&quot; width=&quot;664&quot; height=&quot;488&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GenAI often lacks precise Adjuments&lt;/li&gt;
&lt;li&gt;Tools and Models start CLosing the Gap&lt;/li&gt;
&lt;li&gt;Major Waste of Time and Resources through inefficient Regenerates&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;control-and-hallucinations-in-generated-videos&quot;&gt;Control and hallucinations in generated videos:&lt;/h2&gt;
&lt;p&gt;Generative AI that looks nice, Iâ€™m wondering if the camera turns multiple laps around the guy in the forest, if the color of the jacket on the back would stay the same without having it explicitly described. What do you think, what would happen? ğŸ“¹ğŸ§¥&lt;/p&gt;
&lt;h2 id=&quot;importance-of-genai-control&quot;&gt;Importance of GenAI control:&lt;/h2&gt;
&lt;p&gt;I think overall the opportunity to control generations by precise prompts or other interfaces to further specify intermediate results will be insanely important if these technologies should be adapted in a high efficient outcome-oriented business. We cannot waste time for prompts and regenerates! Cause of time and energy ğŸŒ±â°&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_ai-runway-3d-activity-7259125095783182336-3bZr?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Choosing the Right LLM for Your Needs - Key Considerations</title>
    <link href="https://example.com/blog/241008_choosing_the_right_llm_for_your_needs_key_considerations/" />
    <updated>2024-10-08T00:00:00Z</updated>
    <id>https://example.com/blog/241008_choosing_the_right_llm_for_your_needs_key_considerations/</id>
    <content type="html">&lt;p&gt;Consider the key factors when selecting a Large Language Model (LLM) for your project.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/TSnOnDgQhc-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/TSnOnDgQhc-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/TSnOnDgQhc-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Benchmark Performance&lt;/li&gt;
&lt;li&gt;License&lt;/li&gt;
&lt;li&gt;Model Size&lt;/li&gt;
&lt;li&gt;Alignment&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;key-considerations&quot;&gt;Key Considerations:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“Š &lt;strong&gt;Benchmark Performance:&lt;/strong&gt; Consider the model&#39;s performance on relevant benchmarks known from Open LLM Leaderboard and especially Arena Elo. &lt;a href=&quot;https://lnkd.in/eSkeAUV7&quot;&gt;https://lnkd.in/eSkeAUV7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ“œ &lt;strong&gt;License:&lt;/strong&gt; Ensure the license aligns with your project&#39;s requirements and complies with any regulatory restrictions. &lt;a href=&quot;https://lnkd.in/e8V-eMCh&quot;&gt;https://lnkd.in/e8V-eMCh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ“Š &lt;strong&gt;Model Size:&lt;/strong&gt; Consider the trade-off between model size and performance for your specific use case. &lt;a href=&quot;https://lnkd.in/egZt7BmJ&quot;&gt;https://lnkd.in/egZt7BmJ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ”„ &lt;strong&gt;Alignment:&lt;/strong&gt; Evaluate the alignment process and whether it&#39;s transparent, as this can impact the model&#39;s performance and reliability. &lt;a href=&quot;https://lnkd.in/eViiEyqp&quot;&gt;https://lnkd.in/eViiEyqp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ” &lt;strong&gt;Transparency of Training:&lt;/strong&gt; Look for models with transparent training data and methods to ensure you understand how the model was trained.&lt;/li&gt;
&lt;li&gt;ğŸ’¸ &lt;strong&gt;Inference Costs:&lt;/strong&gt; Assess the model&#39;s inference costs and consider the trade-off between performance and cost. &lt;a href=&quot;https://lnkd.in/etSajZZc&quot;&gt;https://lnkd.in/etSajZZc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ“š &lt;strong&gt;Context Size:&lt;/strong&gt; Consider the model&#39;s context size and whether it&#39;s suitable for your specific use case.&lt;/li&gt;
&lt;li&gt;ğŸ¤ &lt;strong&gt;Compatibility:&lt;/strong&gt; Evaluate whether the model is compatible with SOTA libraries like transformers and whether it&#39;s easily integrable into your workflow.&lt;/li&gt;
&lt;li&gt;ğŸ“ˆ &lt;strong&gt;Scaling Efficiency:&lt;/strong&gt; Assess the model&#39;s scaling efficiency or e.g. it has full quadratic complexity with more input tokens.&lt;/li&gt;
&lt;li&gt;ğŸŒ &lt;strong&gt;Multilingualism:&lt;/strong&gt; Evaluate the model&#39;s multilingual capabilities it&#39;s effect for your specific use case. &lt;a href=&quot;https://lnkd.in/eeVsG99M&quot;&gt;https://lnkd.in/eeVsG99M&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-do-you-think&quot;&gt;What Do You Think?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What is your importance-order of LLM features you look at? Which criteria do you miss in this list or which should be ranked higher?&lt;/li&gt;
&lt;li&gt;Within our Projects Comma Soft AG these are some of the major criteria we look at when we are selecting GenAI models like LLMs.&lt;/li&gt;
&lt;li&gt;If you like to see more of best practice content, follow me, share your thoughts, and leave me a like â¤ï¸&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;#LostInGenai #artificialintelligence #selectllm&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Stop adding Languages to LLMs! The Potential Drawbacks of Training Multilingual Large Language Models (LLMs) for Performance and Sustainability!</title>
    <link href="https://example.com/blog/241001_stop_adding_languages_to_llms_the_potential/" />
    <updated>2024-10-01T00:00:00Z</updated>
    <id>https://example.com/blog/241001_stop_adding_languages_to_llms_the_potential/</id>
    <content type="html">&lt;p&gt;Exploring the downsides of creating multilingual LLMs and their impact on performance and resource utilization.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/JA9fsEHeRy-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/JA9fsEHeRy-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/JA9fsEHeRy-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Challenges of building multilingual LLMs&lt;/li&gt;
&lt;li&gt;Inefficiencies in token usage and context length&lt;/li&gt;
&lt;li&gt;Increased hardware costs and reduced token training&lt;/li&gt;
&lt;li&gt;Weighing multilingual models against language-specific models&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;building-a-multi-lang-llm&quot;&gt;Building a Multi-Lang-LLM ğŸ› ï¸ğŸ£&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;When pretraining LLMs, one of the key decisions is which data to include.&lt;/li&gt;
&lt;li&gt;This choice also influences the selection of the tokenizer, which optimizes the number of tokens for the texts used.&lt;/li&gt;
&lt;li&gt;As a result, different characters and character sequences are mapped in the tokenizers for each language.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;when-you-finally-use-such-a-llm-in-only-a-subset-of-available-languages-you-face-following-problems&quot;&gt;When you finally use such a LLM in only a subset of available languages you face following problems ğŸ‡ªğŸ‡ºğŸ¤–&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Inefficient token usage: If the model is only used for one or two languages, many tokens may be rarely or never needed, leading to shorter token sequences in the required language.&lt;/li&gt;
&lt;li&gt;Limited context length: LLMs have a limited context length, measured in tokens, which can result in more expensive inference as the model scales linearly to quadratically with prompt length.&lt;/li&gt;
&lt;li&gt;Increased hardware costs: This can lead to higher hardware costs and omissions.&lt;/li&gt;
&lt;li&gt;Reduced relevant token training: With a multilingual model, fewer relevant tokens and token sequences may have been seen and trained in the required languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-trade-off-multilingual-models-vs-language-specific-models&quot;&gt;The Trade-Off: Multilingual Models vs. Language-Specific Models ğŸ’°ğŸ“Š&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We need to weigh the benefits of multilingual models against the potential drawbacks and decide whether to prioritize language coverage or risk wasting resources.&lt;/li&gt;
&lt;li&gt;This is particularly important when dealing with languages that are not closely related, such as those with different character sets.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;your-opinion&quot;&gt;Your Opinion ğŸ¤—&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What do you think?&lt;/li&gt;
&lt;li&gt;Have you ever chosen a model especially with reduced number of languages outside English?&lt;/li&gt;
&lt;li&gt;Some more details about Multi-Lang-GenAI can be found here: &lt;a href=&quot;https://lnkd.in/edgPsdKz&quot;&gt;https://lnkd.in/edgPsdKz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more content, follow me or reach out to me over DM â¤ï¸&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai #llm #languages&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-llm-activity-7246524467034689537-nZ-f?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Do we need another GenAI solution? How &amp; why we developed a full-stack GenAI LLM+RAG tool called Alan. A sneak peek at what I am currently working on.</title>
    <link href="https://example.com/blog/240617_do_we_need_another_genai_solution_how_why/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240617_do_we_need_another_genai_solution_how_why/</id>
    <content type="html">&lt;p&gt;An overview of the motivations and technical aspects behind developing our own GenAI solution, Alan, at Comma Soft AG.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/UXAYbK_4C8-986.avif 986w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/UXAYbK_4C8-986.webp 986w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/UXAYbK_4C8-986.png&quot; alt=&quot;Alan PDF&quot; width=&quot;986&quot; height=&quot;668&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diverse GenAI solutions exist&lt;/li&gt;
&lt;li&gt;Unique motivations for developing our own tool&lt;/li&gt;
&lt;li&gt;Technical advantages of our solution&lt;/li&gt;
&lt;li&gt;Questions on custom development vs. wrappers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;current-landscape&quot;&gt;Current Landscape: ğŸï¸&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There are a variety of GenAI solutions out there&lt;/li&gt;
&lt;li&gt;Many models from big tech companies work increasingly well for certain use cases.&lt;/li&gt;
&lt;li&gt;And we have launched our own solution. Why?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;our-technical-perspective&quot;&gt;Our technical perspective: ğŸ¤“&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Data-Flow-Control: We want to know what happens to our data.&lt;/li&gt;
&lt;li&gt;Hosting: We host all our models and data on German servers.&lt;/li&gt;
&lt;li&gt;On-Premise: We can run our entire tech stack on-premise without any internet connection&lt;/li&gt;
&lt;li&gt;Our-own-Alan-Model: We optimize our models for dedicated use cases through further training (e.g., better language skills in GER)&lt;/li&gt;
&lt;li&gt;Knowledge-Enrichment: We decide for ourselves whether we want to make new knowledge available through our novel training approach or through our optimized RAG approach (as you might know there are plenty of options).&lt;/li&gt;
&lt;li&gt;Alignment: We have control over the alignment, i.e., to what extent the values and behaviors of the model match our expectations.&lt;/li&gt;
&lt;li&gt;SOTA: We always remain state of the art in a fusion of existing open source base models and in-house developments.&lt;/li&gt;
&lt;li&gt;Benchmarking: We use benchmarks and measures we trust.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With a great team at Comma Soft AG, it&#39;s enjoyable to develop such a helpful tool â¤ï¸ In the appended PDF we show an extract of the full text story of our ALAN development journey ğŸ“–&lt;/p&gt;
&lt;h2 id=&quot;questions&quot;&gt;Questions: ğŸ¤”&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;How did you decide if you want to develop something yourself or use more kind of wrappers?&lt;/li&gt;
&lt;li&gt;How important is the management of sensitive data for you and where are your servers located?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;literature&quot;&gt;Literature: ğŸ“š&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Here is the full Humboldt Travel Report with more background stories: &lt;a href=&quot;https://lnkd.in/emwvpQsW&quot;&gt;https://lnkd.in/emwvpQsW&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adjusting Model Alignment &lt;a href=&quot;https://lnkd.in/eWS-VZCD&quot;&gt;https://lnkd.in/eWS-VZCD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Model Selection &lt;a href=&quot;https://lnkd.in/duGzWugD&quot;&gt;https://lnkd.in/duGzWugD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Model Benchmarking &lt;a href=&quot;https://lnkd.in/dmBeQZ_j&quot;&gt;https://lnkd.in/dmBeQZ_j&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more GenAI LLM content and R&amp;amp;D discussions, follow me on LinkedIn. If you want to try out Alan, reach out to me: &lt;a href=&quot;http://alan.de&quot;&gt;http://alan.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#artificialintelligence #llm #machinelearning #handson #genai&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_humboldt-travel-report-alan-llm-genai-activity-7208854388101005312-Xr_o?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>DALLE has surprising guardrails. Your image is not filtered based on your prompt. &quot;Dead cookies&quot; may be generated ...sometimes</title>
    <link href="https://example.com/blog/240213_dalle_has_surprising_guardrails/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240213_dalle_has_surprising_guardrails/</id>
    <content type="html">&lt;p&gt;Interesting findings on DALLE&#39;s content filtering mechanisms.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/o3BtZuF2Rz-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/o3BtZuF2Rz-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/o3BtZuF2Rz-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DALLE-3 filters your content AFTER image creation&lt;/li&gt;
&lt;li&gt;With prompt â€œdead cookiesâ€ you can reproduce inconsistent filtering over OpenAI API&lt;/li&gt;
&lt;li&gt;40% of cases with same â€œdead cookiesâ€ prompt stop through content filter and 60% reach us over API&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-is-dalle-3&quot;&gt;What is DALLE-3 ğŸ–¼ï¸&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DALLE 3 is a generative text-to-image model by OpenAI also available as API&lt;/li&gt;
&lt;li&gt;You pay per image&lt;/li&gt;
&lt;li&gt;Images are created based on your prompt like â€œdead cookiesâ€.&lt;/li&gt;
&lt;li&gt;You can also add details like: â€œDead Cookies in cute Pixar styleâ€ or â€œDead cookies with dramatic situation in cute Pixar styleâ€&lt;/li&gt;
&lt;li&gt;Open-Source image GenAI models alternatives are available e.g., Stable Diffusion&lt;/li&gt;
&lt;li&gt;Image GenAI are under discussion because of misuse like deepfakes or reproducing intellectual property.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;finding-observation&quot;&gt;Finding/Observation: ğŸ‘©ğŸ½â€ğŸ”¬&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DALLE-3 has a content filter to reduce misuse&lt;/li&gt;
&lt;li&gt;If you hit the content filter you do not get a resulting image for your prompt.&lt;/li&gt;
&lt;li&gt;The content filter is not applied based on the prompt, it is applied AFTER DALLE-3 generated the image, and the API decides in an extra step if the image should be sent to you. Likely some Image classifier.&lt;/li&gt;
&lt;li&gt;Same prompt sometimes results in an image and sometimes in a content-filter response. For the prompt â€œdead cookiesâ€ you get in 60% of requests an image and in 40% a content filter issue&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;how-we-found-out&quot;&gt;How we found out ğŸª&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We @Comma Soft AG develop tools and pipelines with OS GenAI but also with API requests.&lt;/li&gt;
&lt;li&gt;For good API-response handling, we also had to consider content filter scenarios. So we combined trigger words like &amp;quot;dead&amp;quot; with something like &amp;quot;cookies&amp;quot;&lt;/li&gt;
&lt;li&gt;We had inconsistent content filter and still the finding that in case of content filter the response time was roughly as long as in the case of created image.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions-to-you&quot;&gt;My Questions to you ğŸ¤·ğŸ¼â€â™‚ï¸&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Who should pay for â€œdead cookiesâ€ if the resulting image was created but not sent due to content filter?&lt;/li&gt;
&lt;li&gt;Have you known that the content filter for DALLE-3 is applied after image generation?&lt;/li&gt;
&lt;li&gt;Do you also encounter content filter although your prompts were in principle ok?&lt;/li&gt;
&lt;li&gt;Do you think content filters are a reasonable image GenAI misuse countermeasure?&lt;/li&gt;
&lt;li&gt;How would you reduce Image GenAI misuse?&lt;/li&gt;
&lt;li&gt;And most interesting (and we might never know OpenAI/DALL-E Open Ai), how do â€œDead Cookiesâ€ images look like which are filtered out? ğŸ˜…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The image was created by the prompt &amp;quot;Dead cookies in cute pixar style&amp;quot;
If you like more of such content, reach out to me ğŸ˜Š&lt;/p&gt;
&lt;p&gt;#artificalintelligence #genai #aiethics #dalle #openai #texttoimage #deepfakes&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_artificalintelligence-genai-aiethics-activity-7158865169689821184-J8Y_?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
</feed>