<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="pretty-atom-feed.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>Blog Title</title>
  <subtitle>This is a longer description about your blog.</subtitle>
  <link href="https://example.com/feed/feed.xml" rel="self" />
  <link href="https://example.com/" />
  <updated>2024-12-27T00:00:00Z</updated>
  <id>https://example.com/</id>
  <author>
    <name>Your Name</name>
  </author>
  <entry>
    <title>New DE/EU Open Source LLM 🇪🇺 Teuken 7B, Now Truly Open Source?</title>
    <link href="https://example.com/blog/241127_Teuken_Review/" />
    <updated>2024-12-27T00:00:00Z</updated>
    <id>https://example.com/blog/241127_Teuken_Review/</id>
    <content type="html">&lt;p&gt;New Model out of Open-GPT-X developed within Germany from European Perspective&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/u966D37VBY-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/u966D37VBY-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/u966D37VBY-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;749&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ⏱️&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New German OS LLM&lt;/li&gt;
&lt;li&gt;7B, Transperant Docs&lt;/li&gt;
&lt;li&gt;Problems in Alignment?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;short-facts&quot;&gt;Short Facts&lt;/h2&gt;
&lt;p&gt;🇪🇺 European language focus
🤖 7B parameters
🔗 Very open Apache 2.0 license
🛠️ Instruction Fine-tuned
📊 Not outperforming in Benchmarks but also within normal distribution (for 🇬🇧)
👶🏼 4k max context
💣 (EDIT) Alignment Discussion see here: &lt;a href=&quot;https://lnkd.in/eseXDMMS&quot;&gt;https://lnkd.in/eseXDMMS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My former colleagues Mehdi Ali (roommate within our time in Smart Data Analytics at Rheinische Friedrich-Wilhelms-Universität Bonn of Jens Lehmann) and Stefan Wrobel (one of my Ph.D. supervisors Rheinische Friedrich-Wilhelms-Universität Bonn) and their teams have released an LLM developed in Europe within OpenGPT-X &amp;amp; Fraunhofer IAIS. This has been developed with a focus on European languages. I&#39;m excited to try it out right away and see the actual performance! They announced their own Leaderboard and the Model in somewhere in between other models of same size: &lt;a href=&quot;https://lnkd.in/eTgv8bjV&quot;&gt;https://lnkd.in/eTgv8bjV&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;my-take&quot;&gt;My Take 🤗&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I have high hopes for a better documentation of the development process and I am curious if this model can be called truly open source and not just open weight.&lt;/li&gt;
&lt;li&gt;I look forward to further European and German initiatives that also pursue (Gen)AI development here in 🇪🇺❤️&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions-at-mehdi-ali-michael-fromm-max-luebbering-phd-and-all-your-contributors&quot;&gt;My Questions (at Mehdi Ali, Michael Fromm, Max Lübbering, PhD and all your contributors):&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Is anyone capable to entirely reproduce the model from the documentation?&lt;/li&gt;
&lt;li&gt;What do you expect from Arena Elo Scores?&lt;/li&gt;
&lt;li&gt;In which tasks would you recommend usage of your model over other models from Mistral AI, Meta, Google, Microsoft, Alibaba Cloud like Mistral7B, LLama3.18B, Gemma, Phi, Qwen...&lt;/li&gt;
&lt;li&gt;Will we see truly big LLMs in size of 50-400B Parameter that can compete with current top notch LLMs from your side?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We at Comma Soft AG provide with Alan.de a European and German Solution to use GenAI in a highly performant, safe and trusted environment. If you like to see more of our recent R&amp;amp;D, check my recent posts and reach out to me for more idea exchange 😊&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>We&#39;re Dealing with the Butterfly Effect in LLM Creation Pipelines 🦋🤖</title>
    <link href="https://example.com/blog/241120_were_dealing_with_the_butterfly_effect_in_llm_creation_pipelines/" />
    <updated>2024-11-20T00:00:00Z</updated>
    <id>https://example.com/blog/241120_were_dealing_with_the_butterfly_effect_in_llm_creation_pipelines/</id>
    <content type="html">&lt;p&gt;When we develop novel LLMs, AI-Agents and GenAI Pipelines for Alan.de or within our various other GenAI projects, we&#39;re continuously learning about the Butterfly Effect in GenAI creation pipelines and how to mitigate this problem. 👨🏼‍💻
🤯 Every change can have a huge impact on the entire pipeline that creates and executes models&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/ODUjemRpOm-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/ODUjemRpOm-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/ODUjemRpOm-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ⏱️&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Butterfly Effect can significantly impact LLM creation pipelines.&lt;/li&gt;
&lt;li&gt;Small changes in preprocessing or generation configs can have large ripple effects.&lt;/li&gt;
&lt;li&gt;Constantly evaluating trade-offs and staying up-to-date with new models is crucial.&lt;/li&gt;
&lt;li&gt;Strategies to mitigate the Butterfly Effect are essential for optimal performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-butterfly-effect-in-action&quot;&gt;The Butterfly Effect in action:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;📃 &lt;strong&gt;Example 1:&lt;/strong&gt; Preprocessing differences in raw-document data extraction can result in different extracted text, facts, training and benchmarking data, and ultimately, different model performance and benchmark results.&lt;/li&gt;
&lt;li&gt;📊 &lt;strong&gt;Example 2:&lt;/strong&gt; Even a slight change in the generation config (e.g. top_p) of a Benchmarking-Data generating AI Agent can have a ripple effect on the entire pipeline to the finally selected best LLM.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-challenge&quot;&gt;The Challenge:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;👩🏻‍🔬 With new models and agents (e.g. LLM-as-Judge) becoming available every day, we need to be prepared to exchange components frequently to stay up-to-date and ensure optimal performance and reliability of our pipeline&lt;/li&gt;
&lt;li&gt;⚖️ This means constantly evaluating the trade-offs between performance, reliability, and interpretability, and making informed decisions about when to update or replace components.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-takes&quot;&gt;My Takes:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🧐 Be aware of the Butterfly Effect in your LLM creation pipelines and take steps to mitigate its impact.&lt;/li&gt;
&lt;li&gt;👨🏼‍🎓 Stay up-to-date with the latest developments (insane task) in the field and be prepared to adapt and evolve your solutions accordingly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions&quot;&gt;My Questions:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;🦋 How do you handle the Butterfly Effect in your LLM creation pipelines?&lt;/li&gt;
&lt;li&gt;🗞️ What strategies do you use to stay up-to-date with the latest developments in the field and ensure optimal performance?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In recent and especially upcoming posts I will address how we Comma Soft AG handle this challenge. If you like to see more of the details please leave me a comment what you think and which questions and ideas you have 💬❤️&lt;/p&gt;
&lt;p&gt;#generativeai #artificialintelligence #llm #machinelearning #alan&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>New Official OSI &quot;Open Source AI definition&quot; attacks Meta&#39;s LLAMA as &quot;Open Washing&quot;</title>
    <link href="https://example.com/blog/241113_new_official_osi_open_source_ai_definition_attacks_metas_llama_as_open_washing/" />
    <updated>2024-11-13T00:00:00Z</updated>
    <id>https://example.com/blog/241113_new_official_osi_open_source_ai_definition_attacks_metas_llama_as_open_washing/</id>
    <content type="html">&lt;p&gt;We getting closer what should be considered being open source in GenAI and not only open weight.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/MZY7DxFWA2-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/MZY7DxFWA2-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/MZY7DxFWA2-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR 📝&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official OSI definition of Open Source AI available.&lt;/li&gt;
&lt;li&gt;Meta doesn&#39;t like it 🙅‍♂️.&lt;/li&gt;
&lt;li&gt;State-of-the-art (SOTA) models lack being truly Open Source 🤔.&lt;/li&gt;
&lt;li&gt;&amp;quot;Open Washing&amp;quot; Problem of Meta and others?!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;osi-definition&quot;&gt;OSI Definition 📜&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Publicly accessible training data 📊.&lt;/li&gt;
&lt;li&gt;Publicly accessible code for creation 💻.&lt;/li&gt;
&lt;li&gt;Transparent model weights ⚖️.&lt;/li&gt;
&lt;li&gt;Permissive licensing for usage and modification 📝.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-take&quot;&gt;My Take 🤔&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I mostly agree with the definition of Open Source Initiative (OSI) Open Source AI 👍.&lt;/li&gt;
&lt;li&gt;I hope more SOTA models like LLAMA of Meta would follow this definition when claiming they are Open Source 🤞.&lt;/li&gt;
&lt;li&gt;There is Open Washing out there, either in title (like OpenAI) or in claiming models are open source but not reproducible (training data and sampling and creation pipeline) 🚫.&lt;/li&gt;
&lt;li&gt;I still appreciate that more and more non-fully open source models are available and are at least Open Weight SOTA GenAI models.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;further-reading&quot;&gt;Further Reading 📚&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Problems with Llama &amp;quot;Open Source&amp;quot; License: &lt;a href=&quot;https://lnkd.in/dtStQSdn&quot;&gt;https://lnkd.in/dtStQSdn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;What &amp;quot;Open&amp;quot; Should Truly Mean: &lt;a href=&quot;https://lnkd.in/e7vxhzKi&quot;&gt;https://lnkd.in/e7vxhzKi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OSI Definition: &lt;a href=&quot;https://lnkd.in/ePtGNnvh&quot;&gt;https://lnkd.in/ePtGNnvh&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you ❤️ this content, leave me a thumb up 👍, and please share your thoughts in the comments 💬&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai #opensource #meta #llama&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>The Uncanny Valley Phenomenon in GenAI Face Synthesis</title>
    <link href="https://example.com/blog/241105_the_uncanny_valley_phenomenon_in_genai_face_synthesis/" />
    <updated>2024-11-05T00:00:00Z</updated>
    <id>https://example.com/blog/241105_the_uncanny_valley_phenomenon_in_genai_face_synthesis/</id>
    <content type="html">&lt;p&gt;GenAI hits Uncanny Valley Problems as we have seen in Animation and Computer Games&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/MFdV8_8zRS-946.avif 946w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/MFdV8_8zRS-946.webp 946w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/MFdV8_8zRS-946.png&quot; alt=&quot;Image 1&quot; width=&quot;946&quot; height=&quot;870&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR 📝&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official OSI definition of Open Source AI available.&lt;/li&gt;
&lt;li&gt;Meta doesn&#39;t like it 🙅‍♂️.&lt;/li&gt;
&lt;li&gt;State-of-the-art (SOTA) models lack being truly Open Source 🤔.&lt;/li&gt;
&lt;li&gt;&amp;quot;Open Washing&amp;quot; Problem of Meta and others?!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-is-the-uncanny-valley&quot;&gt;What Is The Uncanny Valley?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The uncanny valley is a phenomenon where human-like objects or characters that are almost, but not quite, indistinguishable from real humans can evoke a sense of eeriness or discomfort. 🤖&lt;/li&gt;
&lt;li&gt;This concept is particularly relevant in the context of generative AI video synthesis of emotional human faces. 📹&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-challenge-of-recreating-lifelike-faces&quot;&gt;The Challenge of Recreating Lifelike Faces&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Creating AI-generated faces that are both realistic and emotionally expressive is a significant challenge. 🤔&lt;/li&gt;
&lt;li&gt;Small imperfections in facial expressions, movements, or emotional nuances can make the synthesized faces appear strange or creepy to viewers. 👻&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-impact-on-emotional-intelligence&quot;&gt;The Impact on Emotional Intelligence&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The uncanny valley phenomenon can have a significant impact on the emotional intelligence of AI systems. 🤖&lt;/li&gt;
&lt;li&gt;If AI-generated faces are not convincingly realistic, they may not be able to evoke the desired emotional response from humans. 🤔&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-do-you-think&quot;&gt;What Do You Think?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Can you think of any potential solutions to overcome the uncanny valley phenomenon in generative AI (face synthesis)? 💡&lt;/li&gt;
&lt;li&gt;Do you believe that the uncanny valley is a significant challenge that needs to be addressed in the development of emotionally intelligent AI systems? 🤔&lt;/li&gt;
&lt;li&gt;Share your thoughts and ideas in the comments! 💬&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;#genai #deeptech #artificialintelligence #uncannyvalley&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>A GenAI Solution/Tweak to Rescue ARD tagesschau webpage?!</title>
    <link href="https://example.com/blog/241025_a_genai_solution_tweak_to_rescue_ard_tagesschau_webpage/" />
    <updated>2024-10-25T00:00:00Z</updated>
    <id>https://example.com/blog/241025_a_genai_solution_tweak_to_rescue_ard_tagesschau_webpage/</id>
    <content type="html">&lt;p&gt;Brainstorming how old regulations meet new GenAI opportunities.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/O_cWA3fM8t-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/O_cWA3fM8t-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/O_cWA3fM8t-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR 📝&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debate over new regulations restricting text content of public broadcasters online.&lt;/li&gt;
&lt;li&gt;Reform could impact news portals like tagesschau.de by limiting text content to only that which accompanies broadcasts.&lt;/li&gt;
&lt;li&gt;GenAI could potentially auto-generate videos from text content to comply with regulations.&lt;/li&gt;
&lt;li&gt;Questions about the impact and regulation of GenAI in public broadcasting contexts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am wondering if my proposed solution would contradict the possible upcoming regulations (see below) 🤔.&lt;/li&gt;
&lt;li&gt;I might be biased as tagesschau.de is for me one good source of news with a mix of text and video while being free of ads 📰(IMHO).&lt;/li&gt;
&lt;li&gt;I am writing this as only one example where old regulations might clash with or ignore recent GenAI developments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Current Debate:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More or less every household needs to pay ~18€ monthly for public broadcast 💶.&lt;/li&gt;
&lt;li&gt;State premiers are discussing a reform that would significantly restrict the text content of public broadcasters like ARD and ZDF online 📄.&lt;/li&gt;
&lt;li&gt;The draft reform mandates that only texts accompanying broadcasts are permitted, meaning text content can only be published if it has been previously covered in a TV broadcast 📺.&lt;/li&gt;
&lt;li&gt;This change would greatly impact the speed and diversity of reporting, particularly for news portals like tagesschau.de, they say 🚫.&lt;/li&gt;
&lt;li&gt;Private publishers, viewing this as a competitive advantage, support the reform, while public broadcaster representatives warn of negative effects on media diversity and information provision 🏢.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;My GenAI Perspective:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What would happen if these platforms autogenerate videos on some digital video stream platform based on the text content they propose? 🤖.&lt;/li&gt;
&lt;li&gt;We have seen such approaches of text-to-video generation or speech synthesis 📝.&lt;/li&gt;
&lt;li&gt;Maybe with a digital clone of some professional or artificial speaker (who needs to allow this for sure and should get paid for giving away the digital twin) 🗣️.&lt;/li&gt;
&lt;li&gt;Currently we face several conflicts of old media and GenAI but this is more between public broadcast and private publishers ⚖️.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do you see it? 🤷.&lt;/li&gt;
&lt;li&gt;Do you think GenAI content would solve their issue? 🤔.&lt;/li&gt;
&lt;li&gt;How is it regulated within your country if public broadcast can write articles? 🌍.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Link to 🇩🇪 Tagesschau article: &lt;a href=&quot;https://lnkd.in/dkx_RZun&quot;&gt;https://lnkd.in/dkx_RZun&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#Rundfunkbeitrag #genai #gez #presse #artificialintelligence&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>We Cannot Waste Time and Resources through Regenerating GenAI Creations! GenAI Control is Key for Productivity!</title>
    <link href="https://example.com/blog/241016_we_cannot_waste_time_and_resources_through_regenerating_genai_creations_genai_control_is_key_for_productivity/" />
    <updated>2024-10-16T00:00:00Z</updated>
    <id>https://example.com/blog/241016_we_cannot_waste_time_and_resources_through_regenerating_genai_creations_genai_control_is_key_for_productivity/</id>
    <content type="html">&lt;p&gt;We will see more and more precise adjustment options in GenAI Tooling&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/DGwfP2s1_T-664.avif 664w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/DGwfP2s1_T-664.webp 664w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/DGwfP2s1_T-664.png&quot; alt=&quot;Image 1&quot; width=&quot;664&quot; height=&quot;488&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ⏱️&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GenAI often lacks precise Adjuments&lt;/li&gt;
&lt;li&gt;Tools and Models start CLosing the Gap&lt;/li&gt;
&lt;li&gt;Major Waste of Time and Resources through inefficient Regenerates&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;control-and-hallucinations-in-generated-videos&quot;&gt;Control and hallucinations in generated videos:&lt;/h2&gt;
&lt;p&gt;Generative AI that looks nice, I’m wondering if the camera turns multiple laps around the guy in the forest, if the color of the jacket on the back would stay the same without having it explicitly described. What do you think, what would happen? 📹🧥&lt;/p&gt;
&lt;h2 id=&quot;importance-of-genai-control&quot;&gt;Importance of GenAI control:&lt;/h2&gt;
&lt;p&gt;I think overall the opportunity to control generations by precise prompts or other interfaces to further specify intermediate results will be insanely important if these technologies should be adapted in a high efficient outcome-oriented business. We cannot waste time for prompts and regenerates! Cause of time and energy 🌱⏰&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_ai-runway-3d-activity-7259125095783182336-3bZr?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Choosing the Right LLM for Your Needs - Key Considerations</title>
    <link href="https://example.com/blog/241008_choosing_the_right_llm_for_your_needs_key_considerations/" />
    <updated>2024-10-08T00:00:00Z</updated>
    <id>https://example.com/blog/241008_choosing_the_right_llm_for_your_needs_key_considerations/</id>
    <content type="html">&lt;p&gt;Consider the key factors when selecting a Large Language Model (LLM) for your project.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/TSnOnDgQhc-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/TSnOnDgQhc-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/TSnOnDgQhc-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ⏱️&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Benchmark Performance&lt;/li&gt;
&lt;li&gt;License&lt;/li&gt;
&lt;li&gt;Model Size&lt;/li&gt;
&lt;li&gt;Alignment&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;key-considerations&quot;&gt;Key Considerations:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;📊 &lt;strong&gt;Benchmark Performance:&lt;/strong&gt; Consider the model&#39;s performance on relevant benchmarks known from Open LLM Leaderboard and especially Arena Elo. &lt;a href=&quot;https://lnkd.in/eSkeAUV7&quot;&gt;https://lnkd.in/eSkeAUV7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;📜 &lt;strong&gt;License:&lt;/strong&gt; Ensure the license aligns with your project&#39;s requirements and complies with any regulatory restrictions. &lt;a href=&quot;https://lnkd.in/e8V-eMCh&quot;&gt;https://lnkd.in/e8V-eMCh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;📊 &lt;strong&gt;Model Size:&lt;/strong&gt; Consider the trade-off between model size and performance for your specific use case. &lt;a href=&quot;https://lnkd.in/egZt7BmJ&quot;&gt;https://lnkd.in/egZt7BmJ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;🔄 &lt;strong&gt;Alignment:&lt;/strong&gt; Evaluate the alignment process and whether it&#39;s transparent, as this can impact the model&#39;s performance and reliability. &lt;a href=&quot;https://lnkd.in/eViiEyqp&quot;&gt;https://lnkd.in/eViiEyqp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;🔍 &lt;strong&gt;Transparency of Training:&lt;/strong&gt; Look for models with transparent training data and methods to ensure you understand how the model was trained.&lt;/li&gt;
&lt;li&gt;💸 &lt;strong&gt;Inference Costs:&lt;/strong&gt; Assess the model&#39;s inference costs and consider the trade-off between performance and cost. &lt;a href=&quot;https://lnkd.in/etSajZZc&quot;&gt;https://lnkd.in/etSajZZc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;📚 &lt;strong&gt;Context Size:&lt;/strong&gt; Consider the model&#39;s context size and whether it&#39;s suitable for your specific use case.&lt;/li&gt;
&lt;li&gt;🤝 &lt;strong&gt;Compatibility:&lt;/strong&gt; Evaluate whether the model is compatible with SOTA libraries like transformers and whether it&#39;s easily integrable into your workflow.&lt;/li&gt;
&lt;li&gt;📈 &lt;strong&gt;Scaling Efficiency:&lt;/strong&gt; Assess the model&#39;s scaling efficiency or e.g. it has full quadratic complexity with more input tokens.&lt;/li&gt;
&lt;li&gt;🌎 &lt;strong&gt;Multilingualism:&lt;/strong&gt; Evaluate the model&#39;s multilingual capabilities it&#39;s effect for your specific use case. &lt;a href=&quot;https://lnkd.in/eeVsG99M&quot;&gt;https://lnkd.in/eeVsG99M&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-do-you-think&quot;&gt;What Do You Think?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What is your importance-order of LLM features you look at? Which criteria do you miss in this list or which should be ranked higher?&lt;/li&gt;
&lt;li&gt;Within our Projects Comma Soft AG these are some of the major criteria we look at when we are selecting GenAI models like LLMs.&lt;/li&gt;
&lt;li&gt;If you like to see more of best practice content, follow me, share your thoughts, and leave me a like ❤️&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;#LostInGenai #artificialintelligence #selectllm&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Stop adding Languages to LLMs! The Potential Drawbacks of Training Multilingual Large Language Models (LLMs) for Performance and Sustainability!</title>
    <link href="https://example.com/blog/241001_stop_adding_languages_to_llms_the_potential/" />
    <updated>2024-10-01T00:00:00Z</updated>
    <id>https://example.com/blog/241001_stop_adding_languages_to_llms_the_potential/</id>
    <content type="html">&lt;p&gt;Exploring the downsides of creating multilingual LLMs and their impact on performance and resource utilization.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/JA9fsEHeRy-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/JA9fsEHeRy-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/JA9fsEHeRy-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ⏱️&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Challenges of building multilingual LLMs&lt;/li&gt;
&lt;li&gt;Inefficiencies in token usage and context length&lt;/li&gt;
&lt;li&gt;Increased hardware costs and reduced token training&lt;/li&gt;
&lt;li&gt;Weighing multilingual models against language-specific models&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;building-a-multi-lang-llm&quot;&gt;Building a Multi-Lang-LLM 🛠️🐣&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;When pretraining LLMs, one of the key decisions is which data to include.&lt;/li&gt;
&lt;li&gt;This choice also influences the selection of the tokenizer, which optimizes the number of tokens for the texts used.&lt;/li&gt;
&lt;li&gt;As a result, different characters and character sequences are mapped in the tokenizers for each language.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;when-you-finally-use-such-a-llm-in-only-a-subset-of-available-languages-you-face-following-problems&quot;&gt;When you finally use such a LLM in only a subset of available languages you face following problems 🇪🇺🤖&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Inefficient token usage: If the model is only used for one or two languages, many tokens may be rarely or never needed, leading to shorter token sequences in the required language.&lt;/li&gt;
&lt;li&gt;Limited context length: LLMs have a limited context length, measured in tokens, which can result in more expensive inference as the model scales linearly to quadratically with prompt length.&lt;/li&gt;
&lt;li&gt;Increased hardware costs: This can lead to higher hardware costs and omissions.&lt;/li&gt;
&lt;li&gt;Reduced relevant token training: With a multilingual model, fewer relevant tokens and token sequences may have been seen and trained in the required languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-trade-off-multilingual-models-vs-language-specific-models&quot;&gt;The Trade-Off: Multilingual Models vs. Language-Specific Models 💰📊&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We need to weigh the benefits of multilingual models against the potential drawbacks and decide whether to prioritize language coverage or risk wasting resources.&lt;/li&gt;
&lt;li&gt;This is particularly important when dealing with languages that are not closely related, such as those with different character sets.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;your-opinion&quot;&gt;Your Opinion 🤗&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What do you think?&lt;/li&gt;
&lt;li&gt;Have you ever chosen a model especially with reduced number of languages outside English?&lt;/li&gt;
&lt;li&gt;Some more details about Multi-Lang-GenAI can be found here: &lt;a href=&quot;https://lnkd.in/edgPsdKz&quot;&gt;https://lnkd.in/edgPsdKz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more content, follow me or reach out to me over DM ❤️&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai #llm #languages&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-llm-activity-7246524467034689537-nZ-f?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Do we need another GenAI solution? How &amp; why we developed a full-stack GenAI LLM+RAG tool called Alan. A sneak peek at what I am currently working on.</title>
    <link href="https://example.com/blog/240617_do_we_need_another_genai_solution_how_why/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240617_do_we_need_another_genai_solution_how_why/</id>
    <content type="html">&lt;p&gt;An overview of the motivations and technical aspects behind developing our own GenAI solution, Alan, at Comma Soft AG.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/UXAYbK_4C8-986.avif 986w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/UXAYbK_4C8-986.webp 986w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/UXAYbK_4C8-986.png&quot; alt=&quot;Alan PDF&quot; width=&quot;986&quot; height=&quot;668&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ⏱️&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diverse GenAI solutions exist&lt;/li&gt;
&lt;li&gt;Unique motivations for developing our own tool&lt;/li&gt;
&lt;li&gt;Technical advantages of our solution&lt;/li&gt;
&lt;li&gt;Questions on custom development vs. wrappers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;current-landscape&quot;&gt;Current Landscape: 🏞️&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There are a variety of GenAI solutions out there&lt;/li&gt;
&lt;li&gt;Many models from big tech companies work increasingly well for certain use cases.&lt;/li&gt;
&lt;li&gt;And we have launched our own solution. Why?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;our-technical-perspective&quot;&gt;Our technical perspective: 🤓&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Data-Flow-Control: We want to know what happens to our data.&lt;/li&gt;
&lt;li&gt;Hosting: We host all our models and data on German servers.&lt;/li&gt;
&lt;li&gt;On-Premise: We can run our entire tech stack on-premise without any internet connection&lt;/li&gt;
&lt;li&gt;Our-own-Alan-Model: We optimize our models for dedicated use cases through further training (e.g., better language skills in GER)&lt;/li&gt;
&lt;li&gt;Knowledge-Enrichment: We decide for ourselves whether we want to make new knowledge available through our novel training approach or through our optimized RAG approach (as you might know there are plenty of options).&lt;/li&gt;
&lt;li&gt;Alignment: We have control over the alignment, i.e., to what extent the values and behaviors of the model match our expectations.&lt;/li&gt;
&lt;li&gt;SOTA: We always remain state of the art in a fusion of existing open source base models and in-house developments.&lt;/li&gt;
&lt;li&gt;Benchmarking: We use benchmarks and measures we trust.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With a great team at Comma Soft AG, it&#39;s enjoyable to develop such a helpful tool ❤️ In the appended PDF we show an extract of the full text story of our ALAN development journey 📖&lt;/p&gt;
&lt;h2 id=&quot;questions&quot;&gt;Questions: 🤔&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;How did you decide if you want to develop something yourself or use more kind of wrappers?&lt;/li&gt;
&lt;li&gt;How important is the management of sensitive data for you and where are your servers located?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;literature&quot;&gt;Literature: 📚&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Here is the full Humboldt Travel Report with more background stories: &lt;a href=&quot;https://lnkd.in/emwvpQsW&quot;&gt;https://lnkd.in/emwvpQsW&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adjusting Model Alignment &lt;a href=&quot;https://lnkd.in/eWS-VZCD&quot;&gt;https://lnkd.in/eWS-VZCD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Model Selection &lt;a href=&quot;https://lnkd.in/duGzWugD&quot;&gt;https://lnkd.in/duGzWugD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Model Benchmarking &lt;a href=&quot;https://lnkd.in/dmBeQZ_j&quot;&gt;https://lnkd.in/dmBeQZ_j&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more GenAI LLM content and R&amp;amp;D discussions, follow me on LinkedIn. If you want to try out Alan, reach out to me: &lt;a href=&quot;http://alan.de&quot;&gt;http://alan.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#artificialintelligence #llm #machinelearning #handson #genai&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_humboldt-travel-report-alan-llm-genai-activity-7208854388101005312-Xr_o?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>DALLE has surprising guardrails. Your image is not filtered based on your prompt. &quot;Dead cookies&quot; may be generated ...sometimes</title>
    <link href="https://example.com/blog/240213_dalle_has_surprising_guardrails/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240213_dalle_has_surprising_guardrails/</id>
    <content type="html">&lt;p&gt;Interesting findings on DALLE&#39;s content filtering mechanisms.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/o3BtZuF2Rz-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/o3BtZuF2Rz-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/o3BtZuF2Rz-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ⏱️&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DALLE-3 filters your content AFTER image creation&lt;/li&gt;
&lt;li&gt;With prompt “dead cookies” you can reproduce inconsistent filtering over OpenAI API&lt;/li&gt;
&lt;li&gt;40% of cases with same “dead cookies” prompt stop through content filter and 60% reach us over API&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-is-dalle-3&quot;&gt;What is DALLE-3 🖼️&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DALLE 3 is a generative text-to-image model by OpenAI also available as API&lt;/li&gt;
&lt;li&gt;You pay per image&lt;/li&gt;
&lt;li&gt;Images are created based on your prompt like “dead cookies”.&lt;/li&gt;
&lt;li&gt;You can also add details like: “Dead Cookies in cute Pixar style” or “Dead cookies with dramatic situation in cute Pixar style”&lt;/li&gt;
&lt;li&gt;Open-Source image GenAI models alternatives are available e.g., Stable Diffusion&lt;/li&gt;
&lt;li&gt;Image GenAI are under discussion because of misuse like deepfakes or reproducing intellectual property.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;finding-observation&quot;&gt;Finding/Observation: 👩🏽‍🔬&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DALLE-3 has a content filter to reduce misuse&lt;/li&gt;
&lt;li&gt;If you hit the content filter you do not get a resulting image for your prompt.&lt;/li&gt;
&lt;li&gt;The content filter is not applied based on the prompt, it is applied AFTER DALLE-3 generated the image, and the API decides in an extra step if the image should be sent to you. Likely some Image classifier.&lt;/li&gt;
&lt;li&gt;Same prompt sometimes results in an image and sometimes in a content-filter response. For the prompt “dead cookies” you get in 60% of requests an image and in 40% a content filter issue&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;how-we-found-out&quot;&gt;How we found out 🍪&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We @Comma Soft AG develop tools and pipelines with OS GenAI but also with API requests.&lt;/li&gt;
&lt;li&gt;For good API-response handling, we also had to consider content filter scenarios. So we combined trigger words like &amp;quot;dead&amp;quot; with something like &amp;quot;cookies&amp;quot;&lt;/li&gt;
&lt;li&gt;We had inconsistent content filter and still the finding that in case of content filter the response time was roughly as long as in the case of created image.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions-to-you&quot;&gt;My Questions to you 🤷🏼‍♂️&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Who should pay for “dead cookies” if the resulting image was created but not sent due to content filter?&lt;/li&gt;
&lt;li&gt;Have you known that the content filter for DALLE-3 is applied after image generation?&lt;/li&gt;
&lt;li&gt;Do you also encounter content filter although your prompts were in principle ok?&lt;/li&gt;
&lt;li&gt;Do you think content filters are a reasonable image GenAI misuse countermeasure?&lt;/li&gt;
&lt;li&gt;How would you reduce Image GenAI misuse?&lt;/li&gt;
&lt;li&gt;And most interesting (and we might never know OpenAI/DALL-E Open Ai), how do “Dead Cookies” images look like which are filtered out? 😅&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The image was created by the prompt &amp;quot;Dead cookies in cute pixar style&amp;quot;
If you like more of such content, reach out to me 😊&lt;/p&gt;
&lt;p&gt;#artificalintelligence #genai #aiethics #dalle #openai #texttoimage #deepfakes&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_artificalintelligence-genai-aiethics-activity-7158865169689821184-J8Y_?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
</feed>