<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="pretty-atom-feed.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>Blog Title</title>
  <subtitle>This is a longer description about your blog.</subtitle>
  <link href="https://example.com/feed/feed.xml" rel="self" />
  <link href="https://example.com/" />
  <updated>2024-09-30T00:00:00Z</updated>
  <id>https://example.com/</id>
  <author>
    <name>Your Name</name>
  </author>
  <entry>
    <title>New DE/EU Open Source LLM ğŸ‡ªğŸ‡º Teuken 7B, Now Truly Open Source?</title>
    <link href="https://example.com/blog/241110_Teuken_Review/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/241110_Teuken_Review/</id>
    <content type="html">&lt;p&gt;New Model out of Open-GPT-X developed within Germany from European Perspective&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/u966D37VBY-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/u966D37VBY-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/u966D37VBY-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;749&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New German OS LLM&lt;/li&gt;
&lt;li&gt;7B, Transperant Docs&lt;/li&gt;
&lt;li&gt;Problems in Alignment?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;short-facts&quot;&gt;Short Facts&lt;/h2&gt;
&lt;p&gt;ğŸ‡ªğŸ‡º European language focus
ğŸ¤– 7B parameters
ğŸ”— Very open Apache 2.0 license
ğŸ› ï¸ Instruction Fine-tuned
ğŸ“Š Not outperforming in Benchmarks but also within normal distribution (for ğŸ‡¬ğŸ‡§)
ğŸ‘¶ğŸ¼ 4k max context
ğŸ’£ (EDIT) Alignment Discussion see here: &lt;a href=&quot;https://lnkd.in/eseXDMMS&quot;&gt;https://lnkd.in/eseXDMMS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My former colleagues Mehdi Ali (roommate within our time in Smart Data Analytics at Rheinische Friedrich-Wilhelms-UniversitÃ¤t Bonn of Jens Lehmann) and Stefan Wrobel (one of my Ph.D. supervisors Rheinische Friedrich-Wilhelms-UniversitÃ¤t Bonn) and their teams have released an LLM developed in Europe within OpenGPT-X &amp;amp; Fraunhofer IAIS. This has been developed with a focus on European languages. I&#39;m excited to try it out right away and see the actual performance! They announced their own Leaderboard and the Model in somewhere in between other models of same size: &lt;a href=&quot;https://lnkd.in/eTgv8bjV&quot;&gt;https://lnkd.in/eTgv8bjV&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;my-take&quot;&gt;My Take ğŸ¤—&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I have high hopes for a better documentation of the development process and I am curious if this model can be called truly open source and not just open weight.&lt;/li&gt;
&lt;li&gt;I look forward to further European and German initiatives that also pursue (Gen)AI development here in ğŸ‡ªğŸ‡ºâ¤ï¸&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions-at-mehdi-ali-michael-fromm-max-luebbering-phd-and-all-your-contributors&quot;&gt;My Questions (at Mehdi Ali, Michael Fromm, Max LÃ¼bbering, PhD and all your contributors):&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Is anyone capable to entirely reproduce the model from the documentation?&lt;/li&gt;
&lt;li&gt;What do you expect from Arena Elo Scores?&lt;/li&gt;
&lt;li&gt;In which tasks would you recommend usage of your model over other models from Mistral AI, Meta, Google, Microsoft, Alibaba Cloud like Mistral7B, LLama3.18B, Gemma, Phi, Qwen...&lt;/li&gt;
&lt;li&gt;Will we see truly big LLMs in size of 50-400B Parameter that can compete with current top notch LLMs from your side?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We at Comma Soft AG provide with Alan.de a European and German Solution to use GenAI in a highly performant, safe and trusted environment. If you like to see more of our recent R&amp;amp;D, check my recent posts and reach out to me for more idea exchange ğŸ˜Š&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>We&#39;re Dealing with the Butterfly Effect in LLM Creation Pipelines ğŸ¦‹ğŸ¤–</title>
    <link href="https://example.com/blog/241108_were_dealing_with_the_butterfly_effect_in_llm_creation_pipelines/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/241108_were_dealing_with_the_butterfly_effect_in_llm_creation_pipelines/</id>
    <content type="html">&lt;p&gt;When we develop novel LLMs, AI-Agents and GenAI Pipelines for Alan.de or within our various other GenAI projects, we&#39;re continuously learning about the Butterfly Effect in GenAI creation pipelines and how to mitigate this problem. ğŸ‘¨ğŸ¼â€ğŸ’»
ğŸ¤¯ Every change can have a huge impact on the entire pipeline that creates and executes models&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/ODUjemRpOm-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/ODUjemRpOm-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/ODUjemRpOm-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Butterfly Effect can significantly impact LLM creation pipelines.&lt;/li&gt;
&lt;li&gt;Small changes in preprocessing or generation configs can have large ripple effects.&lt;/li&gt;
&lt;li&gt;Constantly evaluating trade-offs and staying up-to-date with new models is crucial.&lt;/li&gt;
&lt;li&gt;Strategies to mitigate the Butterfly Effect are essential for optimal performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-butterfly-effect-in-action&quot;&gt;The Butterfly Effect in action:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“ƒ &lt;strong&gt;Example 1:&lt;/strong&gt; Preprocessing differences in raw-document data extraction can result in different extracted text, facts, training and benchmarking data, and ultimately, different model performance and benchmark results.&lt;/li&gt;
&lt;li&gt;ğŸ“Š &lt;strong&gt;Example 2:&lt;/strong&gt; Even a slight change in the generation config (e.g. top_p) of a Benchmarking-Data generating AI Agent can have a ripple effect on the entire pipeline to the finally selected best LLM.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-challenge&quot;&gt;The Challenge:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ‘©ğŸ»â€ğŸ”¬ With new models and agents (e.g. LLM-as-Judge) becoming available every day, we need to be prepared to exchange components frequently to stay up-to-date and ensure optimal performance and reliability of our pipeline&lt;/li&gt;
&lt;li&gt;âš–ï¸ This means constantly evaluating the trade-offs between performance, reliability, and interpretability, and making informed decisions about when to update or replace components.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-takes&quot;&gt;My Takes:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§ Be aware of the Butterfly Effect in your LLM creation pipelines and take steps to mitigate its impact.&lt;/li&gt;
&lt;li&gt;ğŸ‘¨ğŸ¼â€ğŸ“ Stay up-to-date with the latest developments (insane task) in the field and be prepared to adapt and evolve your solutions accordingly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-questions&quot;&gt;My Questions:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ¦‹ How do you handle the Butterfly Effect in your LLM creation pipelines?&lt;/li&gt;
&lt;li&gt;ğŸ—ï¸ What strategies do you use to stay up-to-date with the latest developments in the field and ensure optimal performance?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In recent and especially upcoming posts I will address how we Comma Soft AG handle this challenge. If you like to see more of the details please leave me a comment what you think and which questions and ideas you have ğŸ’¬â¤ï¸&lt;/p&gt;
&lt;p&gt;#generativeai #artificialintelligence #llm #machinelearning #alan&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>We Cannot Waste Time and Resources through Regenerating GenAI Creations! GenAI Control is Key for Productivity!</title>
    <link href="https://example.com/blog/241107_we_cannot_waste_time_and_resources_through_regenerating_genai_creations_genai_control_is_key_for_productivity/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/241107_we_cannot_waste_time_and_resources_through_regenerating_genai_creations_genai_control_is_key_for_productivity/</id>
    <content type="html">&lt;p&gt;We will see more and more precise adjustment options in GenAI Tooling&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/DGwfP2s1_T-664.avif 664w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/DGwfP2s1_T-664.webp 664w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/DGwfP2s1_T-664.png&quot; alt=&quot;Image 1&quot; width=&quot;664&quot; height=&quot;488&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GenAI often lacks precise Adjuments&lt;/li&gt;
&lt;li&gt;Tools and Models start CLosing the Gap&lt;/li&gt;
&lt;li&gt;Major Waste of Time and Resources through inefficient Regenerates&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;control-and-hallucinations-in-generated-videos&quot;&gt;Control and hallucinations in generated videos:&lt;/h2&gt;
&lt;p&gt;Generative AI that looks nice, Iâ€™m wondering if the camera turns multiple laps around the guy in the forest, if the color of the jacket on the back would stay the same without having it explicitly described. What do you think, what would happen? ğŸ“¹ğŸ§¥&lt;/p&gt;
&lt;h2 id=&quot;importance-of-genai-control&quot;&gt;Importance of GenAI control:&lt;/h2&gt;
&lt;p&gt;I think overall the opportunity to control generations by precise prompts or other interfaces to further specify intermediate results will be insanely important if these technologies should be adapted in a high efficient outcome-oriented business. We cannot waste time for prompts and regenerates! Cause of time and energy ğŸŒ±â°&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_ai-runway-3d-activity-7259125095783182336-3bZr?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>New Official OSI &quot;Open Source AI definition&quot; attacks Meta&#39;s LLAMA as &quot;Open Washing&quot;</title>
    <link href="https://example.com/blog/241106_new_official_osi_open_source_ai_definition_attacks_metas_llama_as_open_washing/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/241106_new_official_osi_open_source_ai_definition_attacks_metas_llama_as_open_washing/</id>
    <content type="html">&lt;p&gt;We getting closer what should be considered being open source in GenAI and not only open weight.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/MZY7DxFWA2-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/MZY7DxFWA2-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/MZY7DxFWA2-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ğŸ“&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official OSI definition of Open Source AI available.&lt;/li&gt;
&lt;li&gt;Meta doesn&#39;t like it ğŸ™…â€â™‚ï¸.&lt;/li&gt;
&lt;li&gt;State-of-the-art (SOTA) models lack being truly Open Source ğŸ¤”.&lt;/li&gt;
&lt;li&gt;&amp;quot;Open Washing&amp;quot; Problem of Meta and others?!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;osi-definition&quot;&gt;OSI Definition ğŸ“œ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Publicly accessible training data ğŸ“Š.&lt;/li&gt;
&lt;li&gt;Publicly accessible code for creation ğŸ’».&lt;/li&gt;
&lt;li&gt;Transparent model weights âš–ï¸.&lt;/li&gt;
&lt;li&gt;Permissive licensing for usage and modification ğŸ“.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;my-take&quot;&gt;My Take ğŸ¤”&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I mostly agree with the definition of Open Source Initiative (OSI) Open Source AI ğŸ‘.&lt;/li&gt;
&lt;li&gt;I hope more SOTA models like LLAMA of Meta would follow this definition when claiming they are Open Source ğŸ¤.&lt;/li&gt;
&lt;li&gt;There is Open Washing out there, either in title (like OpenAI) or in claiming models are open source but not reproducible (training data and sampling and creation pipeline) ğŸš«.&lt;/li&gt;
&lt;li&gt;I still appreciate that more and more non-fully open source models are available and are at least Open Weight SOTA GenAI models.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;further-reading&quot;&gt;Further Reading ğŸ“š&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Problems with Llama &amp;quot;Open Source&amp;quot; License: &lt;a href=&quot;https://lnkd.in/dtStQSdn&quot;&gt;https://lnkd.in/dtStQSdn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;What &amp;quot;Open&amp;quot; Should Truly Mean: &lt;a href=&quot;https://lnkd.in/e7vxhzKi&quot;&gt;https://lnkd.in/e7vxhzKi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OSI Definition: &lt;a href=&quot;https://lnkd.in/ePtGNnvh&quot;&gt;https://lnkd.in/ePtGNnvh&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you â¤ï¸ this content, leave me a thumb up ğŸ‘, and please share your thoughts in the comments ğŸ’¬&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai #opensource #meta #llama&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>The Uncanny Valley Phenomenon in GenAI Face Synthesis</title>
    <link href="https://example.com/blog/241105_the_uncanny_valley_phenomenon_in_genai_face_synthesis/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/241105_the_uncanny_valley_phenomenon_in_genai_face_synthesis/</id>
    <content type="html">&lt;p&gt;GenAI hits Uncanny Valley Problems as we have seen in Animation and Computer Games&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/MFdV8_8zRS-946.avif 946w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/MFdV8_8zRS-946.webp 946w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/MFdV8_8zRS-946.png&quot; alt=&quot;Image 1&quot; width=&quot;946&quot; height=&quot;870&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ğŸ“&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Official OSI definition of Open Source AI available.&lt;/li&gt;
&lt;li&gt;Meta doesn&#39;t like it ğŸ™…â€â™‚ï¸.&lt;/li&gt;
&lt;li&gt;State-of-the-art (SOTA) models lack being truly Open Source ğŸ¤”.&lt;/li&gt;
&lt;li&gt;&amp;quot;Open Washing&amp;quot; Problem of Meta and others?!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-is-the-uncanny-valley&quot;&gt;What Is The Uncanny Valley?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The uncanny valley is a phenomenon where human-like objects or characters that are almost, but not quite, indistinguishable from real humans can evoke a sense of eeriness or discomfort. ğŸ¤–&lt;/li&gt;
&lt;li&gt;This concept is particularly relevant in the context of generative AI video synthesis of emotional human faces. ğŸ“¹&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-challenge-of-recreating-lifelike-faces&quot;&gt;The Challenge of Recreating Lifelike Faces&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Creating AI-generated faces that are both realistic and emotionally expressive is a significant challenge. ğŸ¤”&lt;/li&gt;
&lt;li&gt;Small imperfections in facial expressions, movements, or emotional nuances can make the synthesized faces appear strange or creepy to viewers. ğŸ‘»&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-impact-on-emotional-intelligence&quot;&gt;The Impact on Emotional Intelligence&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The uncanny valley phenomenon can have a significant impact on the emotional intelligence of AI systems. ğŸ¤–&lt;/li&gt;
&lt;li&gt;If AI-generated faces are not convincingly realistic, they may not be able to evoke the desired emotional response from humans. ğŸ¤”&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-do-you-think&quot;&gt;What Do You Think?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Can you think of any potential solutions to overcome the uncanny valley phenomenon in generative AI (face synthesis)? ğŸ’¡&lt;/li&gt;
&lt;li&gt;Do you believe that the uncanny valley is a significant challenge that needs to be addressed in the development of emotionally intelligent AI systems? ğŸ¤”&lt;/li&gt;
&lt;li&gt;Share your thoughts and ideas in the comments! ğŸ’¬&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;#genai #deeptech #artificialintelligence #uncannyvalley&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>A GenAI Solution/Tweak to Rescue ARD tagesschau webpage?!</title>
    <link href="https://example.com/blog/241104_a_genai_solution_tweak_to_rescue_ard_tagesschau_webpage/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/241104_a_genai_solution_tweak_to_rescue_ard_tagesschau_webpage/</id>
    <content type="html">&lt;p&gt;Brainstorming how old regulations meet new GenAI opportunities.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/O_cWA3fM8t-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/O_cWA3fM8t-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/O_cWA3fM8t-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR ğŸ“&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debate over new regulations restricting text content of public broadcasters online.&lt;/li&gt;
&lt;li&gt;Reform could impact news portals like tagesschau.de by limiting text content to only that which accompanies broadcasts.&lt;/li&gt;
&lt;li&gt;GenAI could potentially auto-generate videos from text content to comply with regulations.&lt;/li&gt;
&lt;li&gt;Questions about the impact and regulation of GenAI in public broadcasting contexts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am wondering if my proposed solution would contradict the possible upcoming regulations (see below) ğŸ¤”.&lt;/li&gt;
&lt;li&gt;I might be biased as tagesschau.de is for me one good source of news with a mix of text and video while being free of ads ğŸ“°(IMHO).&lt;/li&gt;
&lt;li&gt;I am writing this as only one example where old regulations might clash with or ignore recent GenAI developments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Current Debate:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More or less every household needs to pay ~18â‚¬ monthly for public broadcast ğŸ’¶.&lt;/li&gt;
&lt;li&gt;State premiers are discussing a reform that would significantly restrict the text content of public broadcasters like ARD and ZDF online ğŸ“„.&lt;/li&gt;
&lt;li&gt;The draft reform mandates that only texts accompanying broadcasts are permitted, meaning text content can only be published if it has been previously covered in a TV broadcast ğŸ“º.&lt;/li&gt;
&lt;li&gt;This change would greatly impact the speed and diversity of reporting, particularly for news portals like tagesschau.de, they say ğŸš«.&lt;/li&gt;
&lt;li&gt;Private publishers, viewing this as a competitive advantage, support the reform, while public broadcaster representatives warn of negative effects on media diversity and information provision ğŸ¢.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;My GenAI Perspective:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What would happen if these platforms autogenerate videos on some digital video stream platform based on the text content they propose? ğŸ¤–.&lt;/li&gt;
&lt;li&gt;We have seen such approaches of text-to-video generation or speech synthesis ğŸ“.&lt;/li&gt;
&lt;li&gt;Maybe with a digital clone of some professional or artificial speaker (who needs to allow this for sure and should get paid for giving away the digital twin) ğŸ—£ï¸.&lt;/li&gt;
&lt;li&gt;Currently we face several conflicts of old media and GenAI but this is more between public broadcast and private publishers âš–ï¸.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do you see it? ğŸ¤·.&lt;/li&gt;
&lt;li&gt;Do you think GenAI content would solve their issue? ğŸ¤”.&lt;/li&gt;
&lt;li&gt;How is it regulated within your country if public broadcast can write articles? ğŸŒ.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Link to ğŸ‡©ğŸ‡ª Tagesschau article: &lt;a href=&quot;https://lnkd.in/dkx_RZun&quot;&gt;https://lnkd.in/dkx_RZun&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;#Rundfunkbeitrag #genai #gez #presse #artificialintelligence&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Choosing the Right LLM for Your Needs - Key Considerations</title>
    <link href="https://example.com/blog/240910_choosing_the_right_llm_for_your_needs_key_considerations/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240910_choosing_the_right_llm_for_your_needs_key_considerations/</id>
    <content type="html">&lt;p&gt;Consider the key factors when selecting a Large Language Model (LLM) for your project.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/TSnOnDgQhc-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/TSnOnDgQhc-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/TSnOnDgQhc-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Benchmark Performance&lt;/li&gt;
&lt;li&gt;License&lt;/li&gt;
&lt;li&gt;Model Size&lt;/li&gt;
&lt;li&gt;Alignment&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;key-considerations&quot;&gt;Key Considerations:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“Š &lt;strong&gt;Benchmark Performance:&lt;/strong&gt; Consider the model&#39;s performance on relevant benchmarks known from Open LLM Leaderboard and especially Arena Elo. &lt;a href=&quot;https://lnkd.in/eSkeAUV7&quot;&gt;https://lnkd.in/eSkeAUV7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ“œ &lt;strong&gt;License:&lt;/strong&gt; Ensure the license aligns with your project&#39;s requirements and complies with any regulatory restrictions. &lt;a href=&quot;https://lnkd.in/e8V-eMCh&quot;&gt;https://lnkd.in/e8V-eMCh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ“Š &lt;strong&gt;Model Size:&lt;/strong&gt; Consider the trade-off between model size and performance for your specific use case. &lt;a href=&quot;https://lnkd.in/egZt7BmJ&quot;&gt;https://lnkd.in/egZt7BmJ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ”„ &lt;strong&gt;Alignment:&lt;/strong&gt; Evaluate the alignment process and whether it&#39;s transparent, as this can impact the model&#39;s performance and reliability. &lt;a href=&quot;https://lnkd.in/eViiEyqp&quot;&gt;https://lnkd.in/eViiEyqp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ” &lt;strong&gt;Transparency of Training:&lt;/strong&gt; Look for models with transparent training data and methods to ensure you understand how the model was trained.&lt;/li&gt;
&lt;li&gt;ğŸ’¸ &lt;strong&gt;Inference Costs:&lt;/strong&gt; Assess the model&#39;s inference costs and consider the trade-off between performance and cost. &lt;a href=&quot;https://lnkd.in/etSajZZc&quot;&gt;https://lnkd.in/etSajZZc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ğŸ“š &lt;strong&gt;Context Size:&lt;/strong&gt; Consider the model&#39;s context size and whether it&#39;s suitable for your specific use case.&lt;/li&gt;
&lt;li&gt;ğŸ¤ &lt;strong&gt;Compatibility:&lt;/strong&gt; Evaluate whether the model is compatible with SOTA libraries like transformers and whether it&#39;s easily integrable into your workflow.&lt;/li&gt;
&lt;li&gt;ğŸ“ˆ &lt;strong&gt;Scaling Efficiency:&lt;/strong&gt; Assess the model&#39;s scaling efficiency or e.g. it has full quadratic complexity with more input tokens.&lt;/li&gt;
&lt;li&gt;ğŸŒ &lt;strong&gt;Multilingualism:&lt;/strong&gt; Evaluate the model&#39;s multilingual capabilities it&#39;s effect for your specific use case. &lt;a href=&quot;https://lnkd.in/eeVsG99M&quot;&gt;https://lnkd.in/eeVsG99M&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-do-you-think&quot;&gt;What Do You Think?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What is your importance-order of LLM features you look at? Which criteria do you miss in this list or which should be ranked higher?&lt;/li&gt;
&lt;li&gt;Within our Projects Comma Soft AG these are some of the major criteria we look at when we are selecting GenAI models like LLMs.&lt;/li&gt;
&lt;li&gt;If you like to see more of best practice content, follow me, share your thoughts, and leave me a like â¤ï¸&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;#LostInGenai #artificialintelligence #selectllm&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Stop adding Languages to LLMs! The Potential Drawbacks of Training Multilingual Large Language Models (LLMs) for Performance and Sustainability!</title>
    <link href="https://example.com/blog/240909_stop_adding_languages_to_llms_the_potential/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240909_stop_adding_languages_to_llms_the_potential/</id>
    <content type="html">&lt;p&gt;Exploring the downsides of creating multilingual LLMs and their impact on performance and resource utilization.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/JA9fsEHeRy-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/JA9fsEHeRy-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/JA9fsEHeRy-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;800&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Challenges of building multilingual LLMs&lt;/li&gt;
&lt;li&gt;Inefficiencies in token usage and context length&lt;/li&gt;
&lt;li&gt;Increased hardware costs and reduced token training&lt;/li&gt;
&lt;li&gt;Weighing multilingual models against language-specific models&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;building-a-multi-lang-llm&quot;&gt;Building a Multi-Lang-LLM ğŸ› ï¸ğŸ£&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;When pretraining LLMs, one of the key decisions is which data to include.&lt;/li&gt;
&lt;li&gt;This choice also influences the selection of the tokenizer, which optimizes the number of tokens for the texts used.&lt;/li&gt;
&lt;li&gt;As a result, different characters and character sequences are mapped in the tokenizers for each language.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;when-you-finally-use-such-a-llm-in-only-a-subset-of-available-languages-you-face-following-problems&quot;&gt;When you finally use such a LLM in only a subset of available languages you face following problems ğŸ‡ªğŸ‡ºğŸ¤–&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Inefficient token usage: If the model is only used for one or two languages, many tokens may be rarely or never needed, leading to shorter token sequences in the required language.&lt;/li&gt;
&lt;li&gt;Limited context length: LLMs have a limited context length, measured in tokens, which can result in more expensive inference as the model scales linearly to quadratically with prompt length.&lt;/li&gt;
&lt;li&gt;Increased hardware costs: This can lead to higher hardware costs and omissions.&lt;/li&gt;
&lt;li&gt;Reduced relevant token training: With a multilingual model, fewer relevant tokens and token sequences may have been seen and trained in the required languages.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-trade-off-multilingual-models-vs-language-specific-models&quot;&gt;The Trade-Off: Multilingual Models vs. Language-Specific Models ğŸ’°ğŸ“Š&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We need to weigh the benefits of multilingual models against the potential drawbacks and decide whether to prioritize language coverage or risk wasting resources.&lt;/li&gt;
&lt;li&gt;This is particularly important when dealing with languages that are not closely related, such as those with different character sets.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;your-opinion&quot;&gt;Your Opinion ğŸ¤—&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What do you think?&lt;/li&gt;
&lt;li&gt;Have you ever chosen a model especially with reduced number of languages outside English?&lt;/li&gt;
&lt;li&gt;Some more details about Multi-Lang-GenAI can be found here: &lt;a href=&quot;https://lnkd.in/edgPsdKz&quot;&gt;https://lnkd.in/edgPsdKz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more content, follow me or reach out to me over DM â¤ï¸&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai #llm #languages&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-llm-activity-7246524467034689537-nZ-f?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Where Science Meets Innovation - My personal Highlights &amp; Insights into the PG 2024! Do you have answers to the open Questions?</title>
    <link href="https://example.com/blog/240908_where_science_meets_innovation_my_personal/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240908_where_science_meets_innovation_my_personal/</id>
    <content type="html">&lt;p&gt;Highlights and open questions from the Petersberger GesprÃ¤che (PG) 2024, covering AI, energy transition, chip technologies, and more.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/vuj-G2c0U--2198.avif 2198w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/vuj-G2c0U--2198.webp 2198w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/vuj-G2c0U--2198.png&quot; alt=&quot;PG 2024 Highlights&quot; width=&quot;2198&quot; height=&quot;952&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI and consciousness discussions&lt;/li&gt;
&lt;li&gt;Energy transition and regulatory challenges&lt;/li&gt;
&lt;li&gt;Distributed chip technologies in Europe&lt;/li&gt;
&lt;li&gt;Generative AI in media&lt;/li&gt;
&lt;li&gt;Metaverse applications beyond gaming&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;ai-and-consciousness&quot;&gt;ğŸ§  AI and Consciousness ğŸ§ &lt;/h2&gt;
&lt;p&gt;Joscha Bach from Liquid AI presented on how advancements in AI could potentially redefine our understanding of consciousness. My open question for him is: How does he intend to reliably measure the achievement of AI consciousness in his efforts?&lt;/p&gt;
&lt;h2 id=&quot;scientific-chemical-hands-on-how-to-fix-energy-transition&quot;&gt;ğŸ‘©ğŸ»â€ğŸ”¬ Scientific Chemical Hands on how to fix energy transition ğŸ‘©ğŸ»â€ğŸ”¬&lt;/h2&gt;
&lt;p&gt;As chairman of Alexander von Humboldt Foundation, Robert SchlÃ¶gl delivered an impressively passionate presentation on energy tech for the climate transition and the phasing out of fossil fuels. Besides scientific derivations, he also highlighted significant regulatory issues that hinder successful implementation. I wonder: How these regulations came about, why they are justified if they are (potentially) not scientifically tenable, and how they can now be resolved?&lt;/p&gt;
&lt;h2 id=&quot;efficient-distributed-chip-technologies-from-the-heart-of-europe&quot;&gt;ğŸ‡ªğŸ‡º Efficient Distributed Chip Technologies from the heart of Europe ğŸ‡ªğŸ‡º&lt;/h2&gt;
&lt;p&gt;Christian Mayr from Technische UniversitÃ¤t Dresden discussed the potential and developments possible in Dresden. He mentioned the use of clustered chip technologies to operate LLMs. One of my open questions is: How can LLMs be distributed across tens of thousands of chips while still achieving acceptable inferential latencies?&lt;/p&gt;
&lt;h2 id=&quot;genai-in-media-opportunities-and-risks&quot;&gt;ğŸ“° GenAI in Media, Opportunities and Risks ğŸ“°&lt;/h2&gt;
&lt;p&gt;In further discussions with Sibylle Anderl from ZEIT Verlagsgruppe, we explored the potentials and risks of Generative AI in text, image, and video generation, and how reducing anonymity could potentially restore credibility. My open question: Whether there is a reliable way to recognize these outputs, given that word frequency alone might not be a proof?&lt;/p&gt;
&lt;h2 id=&quot;metaverse-not-only-a-playground&quot;&gt;ğŸ•¹ï¸ Metaverse, not only a Playground? ğŸ•¹ï¸&lt;/h2&gt;
&lt;p&gt;Nico Michels from Siemens presented the potentials of the Metaverse and digital twins. Q: I&#39;d love to see how such models can help even small municipalities with climate adaptation models, regional impact assessments, and improvement options?&lt;/p&gt;
&lt;p&gt;The open questions highlight the stimulating topics the diverse guests who aim to drive positive change with a progressive mindset. I would like to thank Comma Soft AG and everyone involved for organizing this fantastic event, especially Stephan Huthmacher, whose heartfelt dedication makes this recurring, inspiring event possible. â¤ï¸&lt;/p&gt;
&lt;p&gt;Share your thoughts and impressions, I&#39;ll share the streams ğŸ¤—&lt;/p&gt;
&lt;p&gt;#artificialintelligence #genai #sustainability #petersbergergesprÃ¤che&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-sustainability-activity-7243978164564111361-12R6?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Today&#39;s Research Proposal - How to achieve &quot;real&quot; thinking and reasoning in GenAI, rather than just relying on a silent Chain of Thought, as seen in ReflectionAI or possibly GPT-o1?</title>
    <link href="https://example.com/blog/240907_todays_research_proposal_how_to_achieve_real/" />
    <updated>2024-09-30T00:00:00Z</updated>
    <id>https://example.com/blog/240907_todays_research_proposal_how_to_achieve_real/</id>
    <content type="html">&lt;p&gt;Exploring the potential for achieving true reasoning and thinking in Generative AI models beyond the current Chain of Thought methodologies.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/img/W1uRDiZMha-800.avif 800w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/img/W1uRDiZMha-800.webp 800w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/img/W1uRDiZMha-800.jpeg&quot; alt=&quot;Image 1&quot; width=&quot;800&quot; height=&quot;696&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TL;DR â±ï¸&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Current state of reasoning in models&lt;/li&gt;
&lt;li&gt;Possibilities for transformers to learn to think&lt;/li&gt;
&lt;li&gt;Customization ideas for achieving true reasoning&lt;/li&gt;
&lt;li&gt;Open questions and discussion points&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;currently-reasoning-more-through-silent-the-cot&quot;&gt;Currently, reasoning more through silent the CoT ğŸ˜¥&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There are currently models that claim to possess reasoning capabilities.&lt;/li&gt;
&lt;li&gt;However, this is more about the Chain of Thought and the use of special tokens.&lt;/li&gt;
&lt;li&gt;These enable the model to generate more text, thereby increasing the stability of its answers.&lt;/li&gt;
&lt;li&gt;This process of &amp;quot;reasoning&amp;quot; is not transparently/barely shown.&lt;/li&gt;
&lt;li&gt;I believe this is less about reasoning or thinking and more about statistical stability.&lt;/li&gt;
&lt;li&gt;Moreover, it is not possible to observe the reasoning process, and it is often difficult to identify when a model has gone astray.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;how-could-transformers-learn-to-think&quot;&gt;How could transformers learn to think? ğŸ¤¯&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Why can I still imagine that it is possible to learn to think or reason with the transformer architecture?&lt;/li&gt;
&lt;li&gt;Due to the transformer architecture, which includes tokenization, attention, and multi-layer perceptron elements, as well as the universal function approximation hypothesis, the following can be imagined:
&lt;ol&gt;
&lt;li&gt;In early layers, the network learns something akin to named entity recognition.&lt;/li&gt;
&lt;li&gt;Later layers and embedding dimensions create structures that learn propositional logic and structures similar to knowledge graphs or their embeddings.&lt;/li&gt;
&lt;li&gt;Finally, based on this, resonating and reflecting completeness of output logic components could be achieved.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;what-else-would-i-customize-imho&quot;&gt;What else would I customize? ğŸ‘¨ğŸ¼â€ğŸ’» (IMHO)&lt;/h2&gt;
&lt;p&gt;I would find it interesting to combine this with thought-diffusion models, making hierarchical planning possible. I have several more ideas..., reach out to me if you like to start a discussion â¤ï¸&lt;/p&gt;
&lt;h2 id=&quot;questions&quot;&gt;Questions:&lt;/h2&gt;
&lt;p&gt;Are you aware of any approaches or research projects that attempt this?
What are your thoughts on that, how would you build &amp;quot;AGI&amp;quot; it?&lt;/p&gt;
&lt;p&gt;I had great idea exchanges on this with colleagues from Comma Soft AG, Lamarr-Institut &amp;amp; Smart Data Analytics.&lt;/p&gt;
&lt;p&gt;Let&#39;s not waste money and time on believing in marketing claims and rebranding of the word &amp;quot;reasoning&amp;quot;, but let&#39;s start to think of how it could actually be achieved ğŸ¤—&lt;/p&gt;
&lt;p&gt;#AGI #GenAI #artificialintelligence #research&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-sustainability-activity-7243978164564111361-12R6?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;LinkedIn Post&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
</feed>