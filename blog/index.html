<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Carsten Felix Draschner, PhD</title>
		<meta name="description" content="I am writing about my experiences as a naval navel-gazer.">
		<link rel="alternate" href="feed/feed.xml" type="application/atom+xml" title="Carsten Felix Draschner, PhD">
		
		<style>/* This is an arbitrary CSS string added to the bundle */
/* Defaults */
:root {
	--font-family: -apple-system, system-ui, sans-serif;
	--font-family-monospace: Consolas, Menlo, Monaco, Andale Mono WT, Andale Mono, Lucida Console, Lucida Sans Typewriter, DejaVu Sans Mono, Bitstream Vera Sans Mono, Liberation Mono, Nimbus Mono L, Courier New, Courier, monospace;
}

/* Theme colors */
:root {
	--color-gray-20: #e0e0e0;
	--color-gray-50: #C0C0C0;
	--color-gray-90: #333;

	--background-color: #fff;
	--footer-background-color: #333;
	--footer-font-color: #fff;
	--header-background-color: #333;
	--header-font-color: #fff;
	--footer-height: 4rem;

	--text-color: var(--color-gray-90);
	--text-color-link: #082840;
	--text-color-link-active: #4e5f93;
	--text-color-link-visited: #245242;

	--syntax-tab-size: 2;

	--card-background-color: #f9f9f9;
	--card-border-color: #ccc;
}

@media (prefers-color-scheme: dark) {
	:root {
		--color-gray-20: #e0e0e0;
		--color-gray-50: #C0C0C0;
		--color-gray-90: #dad8d8;

		/* --text-color is assigned to --color-gray-_ above */
		--text-color-link: #1493fb;
		--text-color-link-active: #6969f7;
		--text-color-link-visited: #a6a6f8;

		--background-color: #15202b;

		/* Dark mode card colors */
		--card-background-color: #333;
		--card-border-color: #555;
	}
}

.card {
	display: flex;
	align-items: center;
	border: 1px solid var(--card-border-color);
	padding: 10px;
	margin-bottom: 10px;
	border-radius: 8px;
	background-color: var(--card-background-color);
}

.card h3 {
	margin: 0;
  }
  
.card p {
	margin: 0;
}

.card div {
	padding-left: 10px;
}

/* Global stylesheet */
* {
	box-sizing: border-box;
}

@view-transition {
	navigation: auto;
}

html,
body {
	height: 100%;
	padding: 0;
	margin: 0;
	font-family: var(--font-family);
	color: var(--text-color);
	background-color: var(--background-color);
}
html {
	overflow-y: scroll;
}
.color-gray-50{
	color:var(--color-gray-50)
}

img {
    max-width: 100%;
    height: auto;
}


/* .h-excerpt{
	font-size: 1em;
} */

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden {
	clip: rect(0 0 0 0);
	clip-path: inset(50%);
	height: 1px;
	overflow: hidden;
	position: absolute;
	white-space: nowrap;
	width: 1px;
}

p:last-child {
	margin-bottom: 0;
}
p {
	line-height: 1.5;
}

li {
	line-height: 1.5;
}

a[href] {
	color: var(--text-color-link);
}
a[href]:visited {
	color: var(--text-color-link-visited);
}
a[href]:hover,
a[href]:active {
	color: var(--text-color-link-active);
}

main {
	padding: 1rem;
	flex: 1;
	max-width: 40em;
	margin: 0 auto;
	margin-bottom: var(--footer-height);
}
main :first-child {
	margin-top: 0;
}



footer {
	height: var(--footer-height);
    background: var(--footer-background-color);
    color: var(--footer-font-color);
    text-align: center;
    padding: 10px 0;
    bottom: 0;
    width: 100%;
	p {
		height: 100%;
		display: flex;
		align-items: center;
		justify-content: center;
		margin: 0;
	}
}

.links-nextprev {
	display: flex;
	justify-content: space-between;
	gap: .5em 1em;
	list-style: "";
	border-top: 1px dashed var(--color-gray-20);
	padding: 1em 0;
}
.links-nextprev > * {
	flex-grow: 1;
}
.links-nextprev-next {
	text-align: right;
}

table {
	margin: 1em 0;
}
table td,
table th {
	padding-right: 1em;
}

pre,
code {
	font-family: var(--font-family-monospace);
}
pre:not([class*="language-"]) {
	margin: .5em 0;
	line-height: 1.375; /* 22px /16 */
	-moz-tab-size: var(--syntax-tab-size);
	-o-tab-size: var(--syntax-tab-size);
	tab-size: var(--syntax-tab-size);
	-webkit-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
	direction: ltr;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	overflow-x: auto;
}
code {
	word-break: break-all;
}

/* Header */
header {
	background: var(--header-background-color);
	color: var(--header-font-color);
	padding: 1rem 0;
	text-align: center;
	a[href] {
		color: var(--header-font-color);
	}
	a[href]:visited {
		color: var(--header-font-color);
	}
}
.site-title {
	font-size: 2em;
	padding-bottom: 0.4em;
}

.container {
	display: flex; /* Hinzugef√ºgt */
	flex-direction: column; /* Hinzugef√ºgt */
	min-height: 100vh; /* Hinzugef√ºgt */
  }

/* Nav */
.nav {
	display: flex;
	padding: 0;
	margin: 0;
	list-style: none;
    align-items: center;
    flex-direction: row;
    justify-content: center;
}
.nav-item {
	display: inline-block;
	margin-right: 1em;
}
.nav-item a[href]:not(:hover) {
	text-decoration: none;
}
.nav a[href][aria-current="page"] {
	text-decoration: underline;
}

.card {
	display: flex;
	align-items: center;
	border: 1px solid #ccc;
	padding: 10px;
	margin-bottom: 10px;
	border-radius: 8px;
	background-color: var(--background-color);
}
.card img {
	border-radius: 8px;
	height: auto;
	width: 90px;
}
.card .card-title {
	font-size: 1.17em;
	font-weight: bold;
}
.card-navigation ul {
	flex: 1;
	list-style: none;
	padding: 0;
}


@media (prefers-color-scheme: dark) {
	.invert-for-dark-mode {
		filter: invert(100%);
	}
}

/* Posts list */
.postlist {
	list-style: none;
	padding: 0;
}
.postlist-item {
	display: flex;
	flex-wrap: wrap;
	align-items: baseline;
	margin-top: 1em;
	padding-bottom: 1em;
	margin-bottom: 1em;
	border-bottom: 1px solid var(--color-gray-50);
}
.postlist-item:last-child{
	border-bottom: 0;
}

.postlist-date {
	font-size: 0.8125em; /* 13px /16 */
	color: var(--color-gray-90);
}
.postlist-date {
	word-spacing: -0.5px;
}
.postlist-link {
	font-size: 1.1875em; /* 19px /16 */
	font-weight: 700;
	flex-basis: calc(100% - 1.5rem);
	padding-right: .5em;
	text-underline-position: from-font;
	text-underline-offset: 0;
	text-decoration-thickness: 1px;
}
.postlist-item-active .postlist-link {
	font-weight: bold;
}

/* Anchor links next to heading */
.ha-placeholder {
	opacity: 0 !important;
}
h2:has(.ha-placeholder):hover,
h3:has(.ha-placeholder):hover,
h4:has(.ha-placeholder):hover,
h5:has(.ha-placeholder):hover,
h6:has(.ha-placeholder):hover {
	.ha-placeholder {
		opacity: 0.3 !important;
	}
}

/* Tags */
.post-tag {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	text-transform: capitalize;
	font-style: italic;
}
.postlist-item > .post-tag {
	align-self: center;
}

/* Tags list */
.post-metadata {
	display: inline-flex;
	flex-wrap: wrap;
	gap: .5em;
	list-style: none;
	padding: 0;
	margin: 0;
}
.post-metadata time {
	margin-right: 1em;
}</style>
	</head>
	<body>
		<a href="#skip" class="visually-hidden">Skip to main content</a>

		<header>
			<div class="site-title">Carsten Felix Draschner, PhD</div>
			<nav>
				<h2 class="visually-hidden" id="top-level-navigation-menu">Top level navigation menu</h2>
				<ul class="nav">
					<li class="nav-item"><a href="/">Home</a></li>
					<li class="nav-item"><a href="/blog/" aria-current="page">Blog</a></li>
					<li class="nav-item"><a href="/research/">Research</a></li>
					<li class="nav-item"><a href="/projects/">Projects</a></li>
					<li class="nav-item"><a href="/about/">CV</a></li>
					<li class="nav-item"><a href="/contact/">Contact</a></li>
				</ul>
			</nav>
		</header>

		<main id="skip">
			<heading-anchors>
				
<h1 id="blog-posts">Blog Posts</h1>



<ol reversed="" class="postlist">

	<li class="postlist-item">
		<span class="postlist-link">New DE/EU Open Source LLM üá™üá∫ Teuken 7B, Now Truly Open Source?</span>
		<time class="postlist-date" datetime="2024-12-27">December 2024</time>
		<div><p>New Model out of Open-GPT-X developed within Germany from European Perspective</p>
<p><picture><source type="image/avif" srcset="/img/u966D37VBY-800.avif 800w"><source type="image/webp" srcset="/img/u966D37VBY-800.webp 800w"><img loading="lazy" decoding="async" src="/img/u966D37VBY-800.jpeg" alt="Image 1" width="800" height="749"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>New German OS LLM</li>
<li>7B, Transperant Docs</li>
<li>Problems in Alignment?</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241127_Teuken_Review/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/in/carsten-draschner/recent-activity/all/">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">We&#39;re Dealing with the Butterfly Effect in LLM Creation Pipelines ü¶ãü§ñ</span>
		<time class="postlist-date" datetime="2024-11-20">November 2024</time>
		<div><p>When we develop novel LLMs, AI-Agents and GenAI Pipelines for Alan.de or within our various other GenAI projects, we're continuously learning about the Butterfly Effect in GenAI creation pipelines and how to mitigate this problem. üë®üèº‚Äçüíª
ü§Ø Every change can have a huge impact on the entire pipeline that creates and executes models</p>
<p><picture><source type="image/avif" srcset="/img/ODUjemRpOm-800.avif 800w"><source type="image/webp" srcset="/img/ODUjemRpOm-800.webp 800w"><img loading="lazy" decoding="async" src="/img/ODUjemRpOm-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>The Butterfly Effect can significantly impact LLM creation pipelines.</li>
<li>Small changes in preprocessing or generation configs can have large ripple effects.</li>
<li>Constantly evaluating trade-offs and staying up-to-date with new models is crucial.</li>
<li>Strategies to mitigate the Butterfly Effect are essential for optimal performance.</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241120_were_dealing_with_the_butterfly_effect_in_llm_creation_pipelines/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/feed/update/urn:li:activity:7262130122034442240/">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">New Official OSI &quot;Open Source AI definition&quot; attacks Meta&#39;s LLAMA as &quot;Open Washing&quot;</span>
		<time class="postlist-date" datetime="2024-11-13">November 2024</time>
		<div><p>We getting closer what should be considered being open source in GenAI and not only open weight.</p>
<p><picture><source type="image/avif" srcset="/img/MZY7DxFWA2-800.avif 800w"><source type="image/webp" srcset="/img/MZY7DxFWA2-800.webp 800w"><img loading="lazy" decoding="async" src="/img/MZY7DxFWA2-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR üìù</strong></p>
<ul>
<li>Official OSI definition of Open Source AI available.</li>
<li>Meta doesn't like it üôÖ‚Äç‚ôÇÔ∏è.</li>
<li>State-of-the-art (SOTA) models lack being truly Open Source ü§î.</li>
<li>&quot;Open Washing&quot; Problem of Meta and others?!</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241113_new_official_osi_open_source_ai_definition_attacks_metas_llama_as_open_washing/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-opensource-activity-7257413946326892544-c-lj?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">The Uncanny Valley Phenomenon in GenAI Face Synthesis</span>
		<time class="postlist-date" datetime="2024-11-05">November 2024</time>
		<div><p>GenAI hits Uncanny Valley Problems as we have seen in Animation and Computer Games</p>
<p><picture><source type="image/avif" srcset="/img/MFdV8_8zRS-946.avif 946w"><source type="image/webp" srcset="/img/MFdV8_8zRS-946.webp 946w"><img loading="lazy" decoding="async" src="/img/MFdV8_8zRS-946.png" alt="Image 1" width="946" height="870"></picture></p>
<p><strong>TL;DR üìù</strong></p>
<ul>
<li>Official OSI definition of Open Source AI available.</li>
<li>Meta doesn't like it üôÖ‚Äç‚ôÇÔ∏è.</li>
<li>State-of-the-art (SOTA) models lack being truly Open Source ü§î.</li>
<li>&quot;Open Washing&quot; Problem of Meta and others?!</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241105_the_uncanny_valley_phenomenon_in_genai_face_synthesis/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_ai-tech-innovation-activity-7255148987660267520-VImJ?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">A GenAI Solution/Tweak to Rescue ARD tagesschau webpage?!</span>
		<time class="postlist-date" datetime="2024-10-25">October 2024</time>
		<div><p>Brainstorming how old regulations meet new GenAI opportunities.</p>
<p><picture><source type="image/avif" srcset="/img/O_cWA3fM8t-800.avif 800w"><source type="image/webp" srcset="/img/O_cWA3fM8t-800.webp 800w"><img loading="lazy" decoding="async" src="/img/O_cWA3fM8t-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR üìù</strong></p>
<ul>
<li>Debate over new regulations restricting text content of public broadcasters online.</li>
<li>Reform could impact news portals like tagesschau.de by limiting text content to only that which accompanies broadcasts.</li>
<li>GenAI could potentially auto-generate videos from text content to comply with regulations.</li>
<li>Questions about the impact and regulation of GenAI in public broadcasting contexts.</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241025_a_genai_solution_tweak_to_rescue_ard_tagesschau_webpage/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_rundfunkbeitrag-genai-gez-activity-7254856047503282177-bkvA?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">We Cannot Waste Time and Resources through Regenerating GenAI Creations! GenAI Control is Key for Productivity!</span>
		<time class="postlist-date" datetime="2024-10-16">October 2024</time>
		<div><p>We will see more and more precise adjustment options in GenAI Tooling</p>
<p><picture><source type="image/avif" srcset="/img/DGwfP2s1_T-664.avif 664w"><source type="image/webp" srcset="/img/DGwfP2s1_T-664.webp 664w"><img loading="lazy" decoding="async" src="/img/DGwfP2s1_T-664.png" alt="Image 1" width="664" height="488"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>GenAI often lacks precise Adjuments</li>
<li>Tools and Models start CLosing the Gap</li>
<li>Major Waste of Time and Resources through inefficient Regenerates</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241016_we_cannot_waste_time_and_resources_through_regenerating_genai_creations_genai_control_is_key_for_productivity/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_ai-runway-3d-activity-7259125095783182336-3bZr?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Choosing the Right LLM for Your Needs - Key Considerations</span>
		<time class="postlist-date" datetime="2024-10-08">October 2024</time>
		<div><p>Consider the key factors when selecting a Large Language Model (LLM) for your project.</p>
<p><picture><source type="image/avif" srcset="/img/TSnOnDgQhc-800.avif 800w"><source type="image/webp" srcset="/img/TSnOnDgQhc-800.webp 800w"><img loading="lazy" decoding="async" src="/img/TSnOnDgQhc-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Benchmark Performance</li>
<li>License</li>
<li>Model Size</li>
<li>Alignment</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241008_choosing_the_right_llm_for_your_needs_key_considerations/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_lostingenai-artificialintelligence-selectllm-activity-7254502008827658241-5TRJ?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Stop adding Languages to LLMs! The Potential Drawbacks of Training Multilingual Large Language Models (LLMs) for Performance and Sustainability!</span>
		<time class="postlist-date" datetime="2024-10-01">October 2024</time>
		<div><p>Exploring the downsides of creating multilingual LLMs and their impact on performance and resource utilization.</p>
<p><picture><source type="image/avif" srcset="/img/JA9fsEHeRy-800.avif 800w"><source type="image/webp" srcset="/img/JA9fsEHeRy-800.webp 800w"><img loading="lazy" decoding="async" src="/img/JA9fsEHeRy-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Challenges of building multilingual LLMs</li>
<li>Inefficiencies in token usage and context length</li>
<li>Increased hardware costs and reduced token training</li>
<li>Weighing multilingual models against language-specific models</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/241001_stop_adding_languages_to_llms_the_potential/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-llm-activity-7246524467034689537-nZ-f?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Where Science Meets Innovation - My personal Highlights &amp; Insights into the PG 2024! Do you have answers to the open Questions?</span>
		<time class="postlist-date" datetime="2024-09-24">September 2024</time>
		<div><p>Highlights and open questions from the Petersberger Gespr√§che (PG) 2024, covering AI, energy transition, chip technologies, and more.</p>
<p><picture><source type="image/avif" srcset="/img/vuj-G2c0U--2198.avif 2198w"><source type="image/webp" srcset="/img/vuj-G2c0U--2198.webp 2198w"><img loading="lazy" decoding="async" src="/img/vuj-G2c0U--2198.png" alt="PG 2024 Highlights" width="2198" height="952"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>AI and consciousness discussions</li>
<li>Energy transition and regulatory challenges</li>
<li>Distributed chip technologies in Europe</li>
<li>Generative AI in media</li>
<li>Metaverse applications beyond gaming</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240924_where_science_meets_innovation_my_personal/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-sustainability-activity-7243978164564111361-12R6?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Today&#39;s Research Proposal - How to achieve &quot;real&quot; thinking and reasoning in GenAI, rather than just relying on a silent Chain of Thought, as seen in ReflectionAI or possibly GPT-o1?</span>
		<time class="postlist-date" datetime="2024-09-17">September 2024</time>
		<div><p>Exploring the potential for achieving true reasoning and thinking in Generative AI models beyond the current Chain of Thought methodologies.</p>
<p><picture><source type="image/avif" srcset="/img/W1uRDiZMha-800.avif 800w"><source type="image/webp" srcset="/img/W1uRDiZMha-800.webp 800w"><img loading="lazy" decoding="async" src="/img/W1uRDiZMha-800.jpeg" alt="Image 1" width="800" height="696"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Current state of reasoning in models</li>
<li>Possibilities for transformers to learn to think</li>
<li>Customization ideas for achieving true reasoning</li>
<li>Open questions and discussion points</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240917_todays_research_proposal_how_to_achieve_real/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-sustainability-activity-7243978164564111361-12R6?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">For more sustainability transparency in GenAI! Share your knowledge and reduce energy waste!</span>
		<time class="postlist-date" datetime="2024-09-10">September 2024</time>
		<div><p>Emphasizing the importance of transparency and shared knowledge to enhance sustainability in GenAI.</p>
<p><picture><source type="image/avif" srcset="/img/6P9nHx-165-800.avif 800w"><source type="image/webp" srcset="/img/6P9nHx-165-800.webp 800w"><img loading="lazy" decoding="async" src="/img/6P9nHx-165-800.jpeg" alt="Image 1" width="800" height="538"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>GenAI involves very large models and significant training efforts</li>
<li>Transparency can help share emissions and reduce energy waste</li>
<li>Open source models can optimize future development</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240910_for_more_sustainability_transparency_in_genai_share/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_environmental-impact-of-ai-some-model-activity-7236647589096361986-9rSm?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Sustainable Air-Gapped On-Prem LLM Solution! How can we make GenAI available on almost any hardware, and how is it also available as a portable demo on our Alan Notebook</span>
		<time class="postlist-date" datetime="2024-09-03">September 2024</time>
		<div><p>Exploring the development of a full-stack GenAI LLM solution that can run on a variety of hardware configurations, including a portable demo setup.</p>
<p><picture><source type="image/avif" srcset="/img/rVdiXLZ0_K-800.avif 800w"><source type="image/webp" srcset="/img/rVdiXLZ0_K-800.webp 800w"><img loading="lazy" decoding="async" src="/img/rVdiXLZ0_K-800.jpeg" alt="Alan Notebook" width="800" height="879"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Developing Alan, a full-stack GenAI LLM solution</li>
<li>Hosted on German hyperscaler infrastructure</li>
<li>Offers a smaller version, Alan-S-LLM</li>
<li>Portable demo available on Alan Notebook</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240903_sustainable_air_gapped_on_prem_llm_solution/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_genai-onprem-llm-activity-7233851548349444097-lF4N?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Combining the Hugging Face Model Platform and Knowledge Graph trend analysis over time could improve GenAI research and reduce waste of energy!</span>
		<time class="postlist-date" datetime="2024-08-30">August 2024</time>
		<div><p>Exploring the potential of leveraging knowledge graphs to analyze trends in evolving models for better GenAI research and efficiency.</p>
<p><picture><source type="image/avif" srcset="/img/Z0Z_6VvJDf-800.avif 800w"><source type="image/webp" srcset="/img/Z0Z_6VvJDf-800.webp 800w"><img loading="lazy" decoding="async" src="/img/Z0Z_6VvJDf-800.jpeg" alt="Image 1" width="800" height="545"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Leveraging knowledge graphs for GenAI trends</li>
<li>Identifying high-performing models and best practices</li>
<li>Potential for a crowd-sourced GenAI cookbook</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240830_combining_the_hugging_face_model_platform_and_knowledge/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_have-you-noticed-the-new-model-tree-section-activity-7229418184590737409-UoNB?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">What is the perfect approach to adjust an LLM to your GenAI use case?</span>
		<time class="postlist-date" datetime="2024-07-29">July 2024</time>
		<div><p>Exploring various methods to customize LLMs for specific GenAI use cases, ranging from simple to complex approaches.</p>
<p><picture><source type="image/avif" srcset="/img/P0lj_EZjfb-906.avif 906w"><source type="image/webp" srcset="/img/P0lj_EZjfb-906.webp 906w"><img loading="lazy" decoding="async" src="/img/P0lj_EZjfb-906.png" alt="Model Training" width="906" height="335"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Various ways to customize LLMs for specific use cases</li>
<li>Approaches vary in difficulty and complexity</li>
<li>Pros and cons of different methods</li>
<li>More dimensions to improve GenAI use cases</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240729_what_is_the_perfect_approach_to_adjust_an_llm_to_your_genai_use_case/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-llm-activity-7228755735776546817-cUi0?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">These results give me hope for sustainable AI üå±</span>
		<time class="postlist-date" datetime="2024-07-22">July 2024</time>
		<div><p>I'm impressed by some of the recent advances in the field of &quot;small&quot; open-weight Language Models (LLMs).</p>
<p><picture><source type="image/avif" srcset="/img/huHTF98SzS-800.avif 800w"><source type="image/webp" srcset="/img/huHTF98SzS-800.webp 800w"><img loading="lazy" decoding="async" src="/img/huHTF98SzS-800.jpeg" alt="Sustainable AI" width="800" height="450"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Increased documentation supports reproducibility</li>
<li>Data quality improves model performance</li>
<li>Model distillation reduces hardware needs</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240722_these_results_give_me_hope_for_sustainable_ai/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_ai-google-tech-activity-7224785383237001216-HDyZ?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">LLMs - Big vs Small. Bigger is Better!? OR Let&#39;s not waste energy!?</span>
		<time class="postlist-date" datetime="2024-07-15">July 2024</time>
		<div><p>The AI community is abuzz with debates over the efficacy of large versus small language models. Both have their own merits and limitations.</p>
<p><picture><source type="image/avif" srcset="/img/nMmqfr9sVq-907.avif 907w"><source type="image/webp" srcset="/img/nMmqfr9sVq-907.webp 907w"><img loading="lazy" decoding="async" src="/img/nMmqfr9sVq-907.png" alt="Model Size" width="907" height="337"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>AI community debates model sizes</li>
<li>Massive models vs. smaller, efficient models</li>
<li>Insights and future predictions</li>
<li>Links to further reading</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240715_llms_big_vs_small_bigger_is_better_or_lets_not_waste_energy/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_machinelearning-ai-modelsize-activity-7221169255419969536-IQnL?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">GenAI, what is plagiarism? Its Impact on Science. How should it be handled? What is your perspective?</span>
		<time class="postlist-date" datetime="2024-07-08">July 2024</time>
		<div><p>Discussing the implications of GenAI on scientific work and the thin line between acceptable use and plagiarism.</p>
<p><picture><source type="image/avif" srcset="/img/PLpWNuwzop-800.avif 800w"><source type="image/webp" srcset="/img/PLpWNuwzop-800.webp 800w"><img loading="lazy" decoding="async" src="/img/PLpWNuwzop-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Use of GenAI in scientific work</li>
<li>Acceptable vs. debatable vs. critical usage</li>
<li>Questions and concerns about plagiarism</li>
<li>The pressure on researchers and students</li>
<li>Opportunities for better research</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240708_genai_what_is_plagiarism_its_impact/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_genai-plagiarism-research-activity-7216090153457463298-37OX?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Adjust GenAI responses towards more ethical behavior possible through system prompts!? Do you trust in such LLM-chat prepended pamphlets?</span>
		<time class="postlist-date" datetime="2024-07-01">July 2024</time>
		<div><p>Exploring the potential and challenges of using system prompts to guide LLM behavior towards ethical outputs.</p>
<p><picture><source type="image/avif" srcset="/img/x7ZX3a4wEx-800.avif 800w"><source type="image/webp" srcset="/img/x7ZX3a4wEx-800.webp 800w"><img loading="lazy" decoding="async" src="/img/x7ZX3a4wEx-800.jpeg" alt="Ethical AI" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>GenAI chat interactions often include system prompts</li>
<li>System prompts aim to guide ethical LLM behavior</li>
<li>Challenges exist in ensuring compliance and formulation</li>
<li>Questions on designing and revealing system prompts</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240701_adjust_genai_responses_towards_more_ethical_behavior_possible/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-responsibleai-llm-activity-7214141563738750976-ywik?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Alternative to GenAI creativity? Watch and try out these fun Evolutionary Algorithms. Problem-solving without GenAI and SGD-based approaches explained!</span>
		<time class="postlist-date" datetime="2024-06-24">June 2024</time>
		<div><p>Exploring Evolutionary Algorithms as an alternative to GenAI for problem-solving, using a fun 2D vehicle race example.</p>
<p><picture><source type="image/avif" srcset="/img/D6xLKFbtVN-986.avif 986w"><source type="image/webp" srcset="/img/D6xLKFbtVN-986.webp 986w"><img loading="lazy" decoding="async" src="/img/D6xLKFbtVN-986.png" alt="Evo Cars" width="986" height="498"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>There is hype around GenAI and LLMs</li>
<li>Evolutionary Algorithms (EAs) offer an alternative</li>
<li>A fun example of EAs using a 2D vehicle race</li>
<li>Steps involved in EAs explained</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240624_alternative_to_genai_creativity_watch_and_try/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-evolutionaryalgorithms-activity-7211741750673973248-V4Ej?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Fast New ELO Over MixEval. But Looking into Code, I Got Doubts!</span>
		<time class="postlist-date" datetime="2024-06-20">June 2024</time>
		<div><p>Have you seen that MixEval Hard has two interesting but little critical aspects</p>
<p><picture><source type="image/avif" srcset="/img/Qs-Bzleob6-800.avif 800w"><source type="image/webp" srcset="/img/Qs-Bzleob6-800.webp 800w"><img loading="lazy" decoding="async" src="/img/Qs-Bzleob6-800.jpeg" alt="Image 1" width="800" height="745"></picture></p>
<p><strong>TLDR</strong></p>
<ul>
<li>Examined MixEval, an open-source LLM benchmark</li>
<li>Uses LLMs as judges to predict continuous values</li>
<li>Evaluation data contains duplicates</li>
<li>Uncertain about trusting these methods</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240620_MixEval_doubts/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_claude-35-sonnet-ranks-1-on-mixeval-hard-activity-7209826705740361728-Fn3x?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Do we need another GenAI solution? How &amp; why we developed a full-stack GenAI LLM+RAG tool called Alan. A sneak peek at what I am currently working on.</span>
		<time class="postlist-date" datetime="2024-06-17">June 2024</time>
		<div><p>An overview of the motivations and technical aspects behind developing our own GenAI solution, Alan, at Comma Soft AG.</p>
<p><picture><source type="image/avif" srcset="/img/UXAYbK_4C8-986.avif 986w"><source type="image/webp" srcset="/img/UXAYbK_4C8-986.webp 986w"><img loading="lazy" decoding="async" src="/img/UXAYbK_4C8-986.png" alt="Alan PDF" width="986" height="668"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Diverse GenAI solutions exist</li>
<li>Unique motivations for developing our own tool</li>
<li>Technical advantages of our solution</li>
<li>Questions on custom development vs. wrappers</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240617_do_we_need_another_genai_solution_how_why/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_humboldt-travel-report-alan-llm-genai-activity-7208854388101005312-Xr_o?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Will we reach AGI, and if so, by transformers-based architectures? Share your perspective!</span>
		<time class="postlist-date" datetime="2024-06-10">June 2024</time>
		<div><p>Exploring the potential of transformers-based architectures in achieving Artificial General Intelligence (AGI) and the ongoing debate surrounding it.</p>
<p><picture><source type="image/avif" srcset="/img/O7ZY3dL4k4-915.avif 915w"><source type="image/webp" srcset="/img/O7ZY3dL4k4-915.webp 915w"><img loading="lazy" decoding="async" src="/img/O7ZY3dL4k4-915.png" alt="AGI Target" width="915" height="254"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>GenAI's impact on AGI discussions</li>
<li>Technical challenges with transformer-based architectures</li>
<li>Optimistic yet cautious approach at Comma Soft AG</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240610_will_we_reach_agi_and_if/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_%F0%9D%97%AA%F0%9D%97%B6%F0%9D%97%B9%F0%9D%97%B9-%F0%9D%98%84%F0%9D%97%B2-%F0%9D%97%BF%F0%9D%97%B2%F0%9D%97%AE%F0%9D%97%B0%F0%9D%97%B5-%F0%9D%97%94%F0%9D%97%9A%F0%9D%97%9C-%F0%9D%97%AE%F0%9D%97%BB%F0%9D%97%B1-%F0%9D%97%B6%F0%9D%97%B3-activity-7206295399521730561-YPNs?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Do you differentiate AI Ethics principles between AI/ML fields like GenAI/LLMs or Knowledge Graph-based ML? How do we deal with so-called facts on the internet as training data?</span>
		<time class="postlist-date" datetime="2024-06-03">June 2024</time>
		<div><p>Exploring the nuances of AI ethics across different AI/ML fields and handling internet-based training data responsibly.</p>
<p><picture><source type="image/avif" srcset="/img/w-lCvJqaCE-480.avif 480w"><source type="image/webp" srcset="/img/w-lCvJqaCE-480.webp 480w"><img loading="lazy" decoding="async" src="/img/w-lCvJqaCE-480.jpeg" alt="Ethics in AI" width="480" height="436"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>AI ethics principles across different AI/ML fields</li>
<li>Personal background and perspective on AI ethics</li>
<li>Recommendations and further reading on AI ethics</li>
<li>Questions to ponder on AI ethics practices</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240603_do_you_differentiate_ai_ethics/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_aiethics-artificialintelligence-llm-activity-7203778968548720643-SZNh?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">What expectations do you have regarding the values and norms of your GenAI chat assistants? Highly sensitive topic in the LLM space! My take...</span>
		<time class="postlist-date" datetime="2024-05-20">May 2024</time>
		<div><p>Exploring the ethical considerations and expectations surrounding the values and norms embedded in GenAI chat assistants.</p>
<p><picture><source type="image/avif" srcset="/img/nnQxjALsoz-800.avif 800w"><source type="image/webp" srcset="/img/nnQxjALsoz-800.webp 800w"><img loading="lazy" decoding="async" src="/img/nnQxjALsoz-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>LLMs generate text based on training</li>
<li>Alignment and finetuning influence behavior</li>
<li>Ethical considerations in different languages</li>
<li>Need for a holistic view on model behavior</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240520_what_expectations_do_you_have_regarding_the_values_and_norms/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_%F0%9D%97%AA%F0%9D%97%B5%F0%9D%97%AE%F0%9D%98%81-%F0%9D%97%B2%F0%9D%98%85%F0%9D%97%BD%F0%9D%97%B2%F0%9D%97%B0%F0%9D%98%81%F0%9D%97%AE%F0%9D%98%81%F0%9D%97%B6%F0%9D%97%BC%F0%9D%97%BB%F0%9D%98%80-%F0%9D%97%B1%F0%9D%97%BC-%F0%9D%98%86-activity-7196804101395939328-7ck-?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Be careful when you speak of Open (Source) GenAI. Why OpenAI and Meta (shouldn&#39;t) use the word Open within their GenAI efforts?</span>
		<time class="postlist-date" datetime="2024-05-13">May 2024</time>
		<div><p>Examining the implications of using the term &quot;Open&quot; in the context of GenAI by organizations like OpenAI and Meta.</p>
<p><picture><source type="image/avif" srcset="/img/7tnibWsC8h-800.avif 800w"><source type="image/webp" srcset="/img/7tnibWsC8h-800.webp 800w"><img loading="lazy" decoding="async" src="/img/7tnibWsC8h-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR üöÖ</strong></p>
<ul>
<li>Open Source is a huge and important field in computer science and AI</li>
<li>The word &quot;Open&quot; is used widely within the GenAI field: OpenAI, Open Source LLMs</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240513_be_careful_when_you_speak_of_open_source_genai/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-llm-opensource-activity-7193667647274668033-1akX?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Thanks to the Open Source Community for all their efforts! Greetings from PyCon 2024</span>
		<time class="postlist-date" datetime="2024-05-06">May 2024</time>
		<div><p>Expressing gratitude to the open-source community and sharing experiences from PyConDE &amp; PyData Berlin 2024.</p>
<p><picture><source type="image/avif" srcset="/img/jMfYTV6G-2-800.avif 800w"><source type="image/webp" srcset="/img/jMfYTV6G-2-800.webp 800w"><img loading="lazy" decoding="async" src="/img/jMfYTV6G-2-800.jpeg" alt="PyCon 2024" width="800" height="844"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Trip to PyCon with colleagues</li>
<li>Attended insightful talks in various AI fields</li>
<li>Appreciation for open-source community</li>
<li>Gratitude to all contributors and supporters</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240506_thanks_to_the_open_source_community/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_pycon-pycon-pycon-activity-7188549430604636162-2rHg?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Who will take care of truly low-resource languages? A good step towards more fair GenAI LLM pricing at OpenAI for Japanese-using people!</span>
		<time class="postlist-date" datetime="2024-04-29">April 2024</time>
		<div><p>Exploring the challenges and recent developments in addressing low-resource languages within the GenAI landscape, with a focus on OpenAI's efforts for the Japanese language.</p>
<p><picture><source type="image/avif" srcset="/img/MQeZ4f0S9i-800.avif 800w"><source type="image/webp" srcset="/img/MQeZ4f0S9i-800.webp 800w"><img loading="lazy" decoding="async" src="/img/MQeZ4f0S9i-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Issues with LLMs for low-resource languages</li>
<li>Major challenges with different character languages</li>
<li>OpenAI's new dedicated model for Japanese</li>
<li>Concerns about AI ethics and inequality</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240422_who_will_take_care_of_truly_low_resource_languages/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-llm-activity-7186662551923884032-mz7m?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">What is your preferred LLM family? And do you start with an already finetuned LLM? Why you have chosen this LLM? I love to hear your perspective!</span>
		<time class="postlist-date" datetime="2024-04-22">April 2024</time>
		<div><p>Understanding the preferences and choices behind selecting specific LLM families and their finetuned variants.</p>
<p><picture><source type="image/avif" srcset="/img/T2BffE8Afc-894.avif 894w"><source type="image/webp" srcset="/img/T2BffE8Afc-894.webp 894w"><img loading="lazy" decoding="async" src="/img/T2BffE8Afc-894.png" alt="Which Model" width="894" height="341"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>GenAI for text implemented by LLMs</li>
<li>Many open-source models available</li>
<li>Continuous influx of new models</li>
<li>Key foundation model families</li>
<li>LLM-based GenAI pipelines at Comma Soft AG</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240422_what_is_your_preferred_llm_family/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_%F0%9D%97%AA%F0%9D%97%B5%F0%9D%97%AE%F0%9D%98%81-%F0%9D%97%B6%F0%9D%98%80-%F0%9D%98%86%F0%9D%97%BC%F0%9D%98%82%F0%9D%97%BF-%F0%9D%97%BD%F0%9D%97%BF%F0%9D%97%B2%F0%9D%97%B3%F0%9D%97%B2%F0%9D%97%BF%F0%9D%97%BF%F0%9D%97%B2%F0%9D%97%B1-activity-7178654584138067968-rehP?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">NVIDIA Benchmark might be WRONG cause it states - You lose money AND LLM inference speed if you add more NVIDIA A100. This NVIDIA Benchmark is NOT reliable.</span>
		<time class="postlist-date" datetime="2024-04-15">April 2024</time>
		<div><p>Analyzing the reliability of NVIDIA's benchmark results and the implications for LLM inference speed and hardware investment.</p>
<p><picture><source type="image/avif" srcset="/img/DJQnVvOa-c-800.avif 800w"><source type="image/webp" srcset="/img/DJQnVvOa-c-800.webp 800w"><img loading="lazy" decoding="async" src="/img/DJQnVvOa-c-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Terms and background on LLMs and inference</li>
<li>Strange findings in NVIDIA's benchmark results</li>
<li>Concerns about the reliability of these benchmarks</li>
<li>Questions and further reading on the topic</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240415_nvidia_benchmark_might_be_wrong/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_%F0%9D%97%A1%F0%9D%97%A9%F0%9D%97%9C%F0%9D%97%97%F0%9D%97%9C%F0%9D%97%94-%F0%9D%97%95%F0%9D%97%B2%F0%9D%97%BB%F0%9D%97%B0%F0%9D%97%B5%F0%9D%97%BA%F0%9D%97%AE%F0%9D%97%BF%F0%9D%97%B8-%F0%9D%97%BA%F0%9D%97%B6%F0%9D%97%B4%F0%9D%97%B5%F0%9D%98%81-activity-7176105937240231936-KzN2?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Too many LLMs?! How to keep track with all the Open Source Models? Identify the finetuned-masked LLMs and its position within the GenAI landscape!</span>
		<time class="postlist-date" datetime="2024-04-08">April 2024</time>
		<div><p>Navigating the complex landscape of GenAI models can be challenging, but it's crucial to understand the foundational and finetuned models to make informed decisions.</p>
<p><picture><source type="image/avif" srcset="/img/kG9ZmNXJwV-800.avif 800w"><source type="image/webp" srcset="/img/kG9ZmNXJwV-800.webp 800w"><img loading="lazy" decoding="async" src="/img/kG9ZmNXJwV-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>The GenAI landscape is crowded with many models</li>
<li>Keeping track of innovations and true effects is hard</li>
<li>Transparency issues with many so-called &quot;open-source&quot; models</li>
<li>Recommendations for navigating this landscape</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240408_too_many_llms_how_to_keep_track_with_all/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_%F0%9D%97%A7%F0%9D%97%BC%F0%9D%97%BC-%F0%9D%97%BA%F0%9D%97%AE%F0%9D%97%BB%F0%9D%98%86-%F0%9D%97%9F%F0%9D%97%9F%F0%9D%97%A0%F0%9D%98%80-%F0%9D%97%9B%F0%9D%97%BC-%F0%9D%98%81%F0%9D%97%BC-%F0%9D%97%B8-activity-7173581553552318464-6w1Z?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Be careful when you are using LLAMA-2! Legal risks &amp; Sustainability Implications due to LLAMA-2 is (NOT) Open Source.</span>
		<time class="postlist-date" datetime="2024-03-27">March 2024</time>
		<div><p>Important considerations regarding LLAMA-2's legal and sustainability implications.</p>
<p><picture><source type="image/avif" srcset="/img/M1mFzQi1Mm-800.avif 800w"><source type="image/webp" srcset="/img/M1mFzQi1Mm-800.webp 800w"><img loading="lazy" decoding="async" src="/img/M1mFzQi1Mm-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>LLAMA-2's legal and sustainability challenges</li>
<li>Not truly open-source according to OSD</li>
<li>Technical implications of its license</li>
<li>Meta's restrictions and their broader impact</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240327_be_careful_when_you_are_using_llama/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-machinelearning-llm-activity-7170381681563021312-_A5j?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">The major players in GenAI are facing challenges with their Generative AIs. GenAI capabilities and security issues related to LLMs Tools ‚Ä¢ 37C3 Presentation</span>
		<time class="postlist-date" datetime="2024-03-13">March 2024</time>
		<div><p>Challenges and security issues in GenAI and LLMs, highlighted at 37C3.</p>
<p><picture><source type="image/avif" srcset="/img/P4S2SzLLQt-800.avif 800w"><source type="image/webp" srcset="/img/P4S2SzLLQt-800.webp 800w"><img loading="lazy" decoding="async" src="/img/P4S2SzLLQt-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>GenAI has immense capabilities</li>
<li>Ethical and secure GenAI pipelines are crucial</li>
<li>37C3 presentation on security issues and exploitations</li>
<li>Categories of threats and challenges in GenAI</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240313_the_major_players_in_genai_are_facing_challenges/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_generativeai-llm-aisecurity-activity-7167923469148475392-plqf?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Not prompting in English?... You have Problems!! LLM Language Barriers ‚Ä¢ Democratizing GenAI and fair pricing</span>
		<time class="postlist-date" datetime="2024-03-07">March 2024</time>
		<div><p>Exploring the challenges of using Generative AI with languages other than English and the implications for cost and performance.</p>
<p><picture><source type="image/avif" srcset="/img/fWlGlDmFaC-800.avif 800w"><source type="image/webp" srcset="/img/fWlGlDmFaC-800.webp 800w"><img loading="lazy" decoding="async" src="/img/fWlGlDmFaC-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Tokenizers and their role in LLMs</li>
<li>Challenges of non-English prompts</li>
<li>Efficiency and fairness in GenAI</li>
<li>Recommendations for LLM pipelines</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240307_not_prompting_in_english/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_genrativeai-artificialintelligence-machinelearning-activity-7165320754878730242-CICO?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Ever wondered about open source LLLM sizes - 7B, 13B, 70B?</span>
		<time class="postlist-date" datetime="2024-02-27">February 2024</time>
		<div><p>Where do those model sizes come from?... My findings!</p>
<p><picture><source type="image/avif" srcset="/img/Om6W9Bb879-800.avif 800w"><source type="image/webp" srcset="/img/Om6W9Bb879-800.webp 800w"><img loading="lazy" decoding="async" src="/img/Om6W9Bb879-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Open-source LLM alternatives to AIaaS</li>
<li>Hugging Face as a source for open-source models</li>
<li>Many models are finetuned variants</li>
<li>Bigger models imply slower inference &amp; higher costs</li>
<li>Different use cases require different model capabilities</li>
<li>Questioning the parameter step sizes of models</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240227_ever_wondered_about_open_source_llm_sizes/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-maschinelearning-activity-7163192285034172416-AItW?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">We&#39;ve beaten GPT4! ... is a sentence which starts to annoy me.</span>
		<time class="postlist-date" datetime="2024-02-20">February 2024</time>
		<div><p>About Mistrust in LLM Evaluation. Benchmark contamination in LLMs? How to Evaluate GenAI?!</p>
<p><picture><source type="image/avif" srcset="/img/MpNnbxOBA7-800.avif 800w"><source type="image/webp" srcset="/img/MpNnbxOBA7-800.webp 800w"><img loading="lazy" decoding="async" src="/img/MpNnbxOBA7-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>ùóßùóü;ùóóùó• ‚è±Ô∏è</strong></p>
<ul>
<li>News is flooded with LLMs being ‚Äúbetter‚Äù than GPT4</li>
<li>LLM Evaluation is Difficult</li>
<li>Benchmark Contamination is a serious issue</li>
<li>Build your own use case specific benchmarks</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240220_beaten_gpt4/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_generativeai-artificialintelligence-llm-activity-7160295294906101761-koWS?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">DALLE has surprising guardrails. Your image is not filtered based on your prompt. &quot;Dead cookies&quot; may be generated ...sometimes</span>
		<time class="postlist-date" datetime="2024-02-13">February 2024</time>
		<div><p>Interesting findings on DALLE's content filtering mechanisms.</p>
<p><picture><source type="image/avif" srcset="/img/o3BtZuF2Rz-800.avif 800w"><source type="image/webp" srcset="/img/o3BtZuF2Rz-800.webp 800w"><img loading="lazy" decoding="async" src="/img/o3BtZuF2Rz-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>DALLE-3 filters your content AFTER image creation</li>
<li>With prompt ‚Äúdead cookies‚Äù you can reproduce inconsistent filtering over OpenAI API</li>
<li>40% of cases with same ‚Äúdead cookies‚Äù prompt stop through content filter and 60% reach us over API</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240213_dalle_has_surprising_guardrails/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_artificalintelligence-genai-aiethics-activity-7158865169689821184-J8Y_?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">Evil LLMs available! Break GenAI Alignment through finetuning!</span>
		<time class="postlist-date" datetime="2024-02-05">February 2024</time>
		<div><p>Need for LLM Alignment transparency?</p>
<p><picture><source type="image/avif" srcset="/img/MOsgr5omJS-1002.avif 1002w"><source type="image/webp" srcset="/img/MOsgr5omJS-1002.webp 1002w"><img loading="lazy" decoding="async" src="/img/MOsgr5omJS-1002.png" alt="Image 1" width="1002" height="1002"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Powerful LLMs are mostly aligned</li>
<li>Alignment can be broken through finetuning</li>
<li>Need for transparency in alignment processes</li>
<li>Questions about alignment in LLMs</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240205_evil_llms_available_break_genai/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_what-happens-when-you-break-llm-alignment-activity-7157765084734214144-2yGt?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

	<li class="postlist-item">
		<span class="postlist-link">LLAMA2 13B is faster than LLAMA2 7B, according to NVIDIA benchmark!</span>
		<time class="postlist-date" datetime="2024-02-05">February 2024</time>
		<div><p>Interesting findings on NVIDIA's LLAMA 2 benchmark results.</p>
<p><picture><source type="image/avif" srcset="/img/BlZjtzJTkc-800.avif 800w"><source type="image/webp" srcset="/img/BlZjtzJTkc-800.webp 800w"><img loading="lazy" decoding="async" src="/img/BlZjtzJTkc-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>NVIDIA LLAMA 2 Benchmark results</li>
<li>LLAMA 13B reported faster than LLAMA 7B</li>
<li>Questions about the accuracy of these findings</li>
<li>Seeking community insights</li>
</ul>
</div>
		(<a class="color-gray-50" href="/blog/240202_llama2_13b_is_faster_than_llama2_7b/">Read More</a>)&nbsp;&nbsp;(<a class="color-gray-50" href="https://www.linkedin.com/posts/carsten-draschner_genai-machinelearning-llama-activity-7156292445465419776-li69?utm_source=share&amp;utm_medium=member_desktop">Original-Websource</a>)
	</li>

</ol>



			</heading-anchors>
		</main>

		<footer>
			<p>&copy; 2024 Carsten Felix Draschner, PhD</p>
		</footer>

		<!-- This page `/blog/` was built on 2025-01-06T21:41:50.249Z -->
		<script type="module" src="/dist/rJ3_G-2ArF.js"></script>
	</body>
</html>
