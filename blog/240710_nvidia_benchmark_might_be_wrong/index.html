<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>NVIDIA Benchmark might be WRONG cause it states - You lose money AND LLM inference speed if you add more NVIDIA A100. This NVIDIA Benchmark is NOT reliable.</title>
		<meta name="description" content="I am writing about my experiences as a naval navel-gazer.">
		<link rel="alternate" href="feed/feed.xml" type="application/atom+xml" title="Carsten Felix Draschner, PhD">
		
		<style>/**
 * okaidia theme for JavaScript, CSS and HTML
 * Loosely based on Monokai textmate theme by http://www.monokai.nl/
 * @author ocodia
 */

code[class*="language-"],
pre[class*="language-"] {
	color: #f8f8f2;
	background: none;
	text-shadow: 0 1px rgba(0, 0, 0, 0.3);
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	font-size: 1em;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
	border-radius: 0.3em;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #272822;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: #8292a2;
}

.token.punctuation {
	color: #f8f8f2;
}

.token.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.constant,
.token.symbol,
.token.deleted {
	color: #f92672;
}

.token.boolean,
.token.number {
	color: #ae81ff;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #a6e22e;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string,
.token.variable {
	color: #f8f8f2;
}

.token.atrule,
.token.attr-value,
.token.function,
.token.class-name {
	color: #e6db74;
}

.token.keyword {
	color: #66d9ef;
}

.token.regex,
.token.important {
	color: #fd971f;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}
/*
 * New diff- syntax
 */

pre[class*="language-diff-"] {
	--eleventy-code-padding: 1.25em;
	padding-left: var(--eleventy-code-padding);
	padding-right: var(--eleventy-code-padding);
}
.token.deleted {
	background-color: hsl(0, 51%, 37%);
	color: inherit;
}
.token.inserted {
	background-color: hsl(126, 31%, 39%);
	color: inherit;
}

/* Make the + and - characters unselectable for copy/paste */
.token.prefix.unchanged,
.token.prefix.inserted,
.token.prefix.deleted {
	-webkit-user-select: none;
	user-select: none;
	display: inline-flex;
	align-items: center;
	justify-content: center;
	padding-top: 2px;
	padding-bottom: 2px;
}
.token.prefix.inserted,
.token.prefix.deleted {
	width: var(--eleventy-code-padding);
	background-color: rgba(0,0,0,.2);
}

/* Optional: full-width background color */
.token.inserted:not(.prefix),
.token.deleted:not(.prefix) {
	display: block;
	margin-left: calc(-1 * var(--eleventy-code-padding));
	margin-right: calc(-1 * var(--eleventy-code-padding));
	text-decoration: none; /* override del, ins, mark defaults */
	color: inherit; /* override del, ins, mark defaults */
}
/* This is an arbitrary CSS string added to the bundle */
/* Defaults */
:root {
	--font-family: -apple-system, system-ui, sans-serif;
	--font-family-monospace: Consolas, Menlo, Monaco, Andale Mono WT, Andale Mono, Lucida Console, Lucida Sans Typewriter, DejaVu Sans Mono, Bitstream Vera Sans Mono, Liberation Mono, Nimbus Mono L, Courier New, Courier, monospace;
}

/* Theme colors */
:root {
	--color-gray-20: #e0e0e0;
	--color-gray-50: #C0C0C0;
	--color-gray-90: #333;

	--background-color: #fff;
	--footer-background-color: #333;
	--footer-font-color: #fff;
	--header-background-color: #333;
	--header-font-color: #fff;
	--footer-height: 4rem;

	--text-color: var(--color-gray-90);
	--text-color-link: #082840;
	--text-color-link-active: #4e5f93;
	--text-color-link-visited: #245242;

	--syntax-tab-size: 2;

	--card-background-color: #f9f9f9;
	--card-border-color: #ccc;
}

@media (prefers-color-scheme: dark) {
	:root {
		--color-gray-20: #e0e0e0;
		--color-gray-50: #C0C0C0;
		--color-gray-90: #dad8d8;

		/* --text-color is assigned to --color-gray-_ above */
		--text-color-link: #1493fb;
		--text-color-link-active: #6969f7;
		--text-color-link-visited: #a6a6f8;

		--background-color: #15202b;

		/* Dark mode card colors */
		--card-background-color: #333;
		--card-border-color: #555;
	}
}

.card {
	display: flex;
	align-items: center;
	border: 1px solid var(--card-border-color);
	padding: 10px;
	margin-bottom: 10px;
	border-radius: 8px;
	background-color: var(--card-background-color);
}

.card h3 {
	margin: 0;
  }
  
.card p {
	margin: 0;
}

.card div {
	padding-left: 10px;
}

/* Global stylesheet */
* {
	box-sizing: border-box;
}

@view-transition {
	navigation: auto;
}

html,
body {
	height: 100%;
	padding: 0;
	margin: 0;
	font-family: var(--font-family);
	color: var(--text-color);
	background-color: var(--background-color);
}
html {
	overflow-y: scroll;
}
.color-gray-50{
	color:var(--color-gray-50)
}

img {
    max-width: 100%;
    height: auto;
}


/* .h-excerpt{
	font-size: 1em;
} */

/* https://www.a11yproject.com/posts/how-to-hide-content/ */
.visually-hidden {
	clip: rect(0 0 0 0);
	clip-path: inset(50%);
	height: 1px;
	overflow: hidden;
	position: absolute;
	white-space: nowrap;
	width: 1px;
}

p:last-child {
	margin-bottom: 0;
}
p {
	line-height: 1.5;
}

li {
	line-height: 1.5;
}

a[href] {
	color: var(--text-color-link);
}
a[href]:visited {
	color: var(--text-color-link-visited);
}
a[href]:hover,
a[href]:active {
	color: var(--text-color-link-active);
}

main {
	padding: 1rem;
	flex: 1;
	max-width: 40em;
	margin: 0 auto;
	margin-bottom: var(--footer-height);
}
main :first-child {
	margin-top: 0;
}



footer {
	height: var(--footer-height);
    background: var(--footer-background-color);
    color: var(--footer-font-color);
    text-align: center;
    padding: 10px 0;
    bottom: 0;
    width: 100%;
	p {
		height: 100%;
		display: flex;
		align-items: center;
		justify-content: center;
		margin: 0;
	}
}

.links-nextprev {
	display: flex;
	justify-content: space-between;
	gap: .5em 1em;
	list-style: "";
	border-top: 1px dashed var(--color-gray-20);
	padding: 1em 0;
}
.links-nextprev > * {
	flex-grow: 1;
}
.links-nextprev-next {
	text-align: right;
}

table {
	margin: 1em 0;
}
table td,
table th {
	padding-right: 1em;
}

pre,
code {
	font-family: var(--font-family-monospace);
}
pre:not([class*="language-"]) {
	margin: .5em 0;
	line-height: 1.375; /* 22px /16 */
	-moz-tab-size: var(--syntax-tab-size);
	-o-tab-size: var(--syntax-tab-size);
	tab-size: var(--syntax-tab-size);
	-webkit-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
	direction: ltr;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	overflow-x: auto;
}
code {
	word-break: break-all;
}

/* Header */
header {
	background: var(--header-background-color);
	color: var(--header-font-color);
	padding: 1rem 0;
	text-align: center;
	a[href] {
		color: var(--header-font-color);
	}
	a[href]:visited {
		color: var(--header-font-color);
	}
}
.site-title {
	font-size: 2em;
	padding-bottom: 0.4em;
}

.container {
	display: flex; /* Hinzugef√ºgt */
	flex-direction: column; /* Hinzugef√ºgt */
	min-height: 100vh; /* Hinzugef√ºgt */
  }

/* Nav */
.nav {
	display: flex;
	padding: 0;
	margin: 0;
	list-style: none;
    align-items: center;
    flex-direction: row;
    justify-content: center;
}
.nav-item {
	display: inline-block;
	margin-right: 1em;
}
.nav-item a[href]:not(:hover) {
	text-decoration: none;
}
.nav a[href][aria-current="page"] {
	text-decoration: underline;
}

.card {
	display: flex;
	align-items: center;
	border: 1px solid #ccc;
	padding: 10px;
	margin-bottom: 10px;
	border-radius: 8px;
	background-color: var(--background-color);
}
.card img {
	border-radius: 8px;
	height: auto;
	width: 90px;
}
.card .card-title {
	font-size: 1.17em;
	font-weight: bold;
}
.card-navigation ul {
	flex: 1;
	list-style: none;
	padding: 0;
}


@media (prefers-color-scheme: dark) {
	.invert-for-dark-mode {
		filter: invert(100%);
	}
}

/* Posts list */
.postlist {
	list-style: none;
	padding: 0;
}
.postlist-item {
	display: flex;
	flex-wrap: wrap;
	align-items: baseline;
	margin-top: 1em;
	padding-bottom: 1em;
	margin-bottom: 1em;
	border-bottom: 1px solid var(--color-gray-50);
}
.postlist-item:last-child{
	border-bottom: 0;
}

.postlist-date {
	font-size: 0.8125em; /* 13px /16 */
	color: var(--color-gray-90);
}
.postlist-date {
	word-spacing: -0.5px;
}
.postlist-link {
	font-size: 1.1875em; /* 19px /16 */
	font-weight: 700;
	flex-basis: calc(100% - 1.5rem);
	padding-right: .5em;
	text-underline-position: from-font;
	text-underline-offset: 0;
	text-decoration-thickness: 1px;
}
.postlist-item-active .postlist-link {
	font-weight: bold;
}

/* Anchor links next to heading */
.ha-placeholder {
	opacity: 0 !important;
}
h2:has(.ha-placeholder):hover,
h3:has(.ha-placeholder):hover,
h4:has(.ha-placeholder):hover,
h5:has(.ha-placeholder):hover,
h6:has(.ha-placeholder):hover {
	.ha-placeholder {
		opacity: 0.3 !important;
	}
}

/* Tags */
.post-tag {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	text-transform: capitalize;
	font-style: italic;
}
.postlist-item > .post-tag {
	align-self: center;
}

/* Tags list */
.post-metadata {
	display: inline-flex;
	flex-wrap: wrap;
	gap: .5em;
	list-style: none;
	padding: 0;
	margin: 0;
}
.post-metadata time {
	margin-right: 1em;
}</style>
	</head>
	<body>
		<a href="#skip" class="visually-hidden">Skip to main content</a>

		<header>
			<div class="site-title">Carsten Felix Draschner, PhD</div>
			<nav>
				<h2 class="visually-hidden" id="top-level-navigation-menu">Top level navigation menu</h2>
				<ul class="nav">
					<li class="nav-item"><a href="/">Home</a></li>
					<li class="nav-item"><a href="/blog/">Blog</a></li>
					<li class="nav-item"><a href="/research/">Research</a></li>
					<li class="nav-item"><a href="/projects/">Projects</a></li>
					<li class="nav-item"><a href="/about/">CV</a></li>
					<li class="nav-item"><a href="/contact/">Contact</a></li>
				</ul>
			</nav>
		</header>

		<main id="skip">
			<heading-anchors>
				
<h1 id="nvidia-benchmark-might-be-wrong-cause-it-states-you-lose-money-and-llm-inference-speed-if-you-add-more-nvidia-a100-this-nvidia-benchmark-is-not-reliable">NVIDIA Benchmark might be WRONG cause it states - You lose money AND LLM inference speed if you add more NVIDIA A100. This NVIDIA Benchmark is NOT reliable.</h1>

<ul class="post-metadata">
	<li><time datetime="2024-09-30">30 September 2024</time></li>
	<li><a href="/tags/blog/" class="post-tag">blog</a></li>
</ul>


<p>Analyzing the reliability of NVIDIA's benchmark results and the implications for LLM inference speed and hardware investment.</p>
<p><picture><source type="image/avif" srcset="/img/DJQnVvOa-c-800.avif 800w"><source type="image/webp" srcset="/img/DJQnVvOa-c-800.webp 800w"><img loading="lazy" decoding="async" src="/img/DJQnVvOa-c-800.jpeg" alt="Image 1" width="800" height="800"></picture></p>
<p><strong>TL;DR ‚è±Ô∏è</strong></p>
<ul>
<li>Terms and background on LLMs and inference</li>
<li>Strange findings in NVIDIA's benchmark results</li>
<li>Concerns about the reliability of these benchmarks</li>
<li>Questions and further reading on the topic</li>
</ul>
<h2 id="terms">Terms üè´</h2>
<ul>
<li>LLMs are Large Language Models</li>
<li>LLMs are a branch of Generative AI</li>
<li>Those LLMs can be used to generate texts</li>
<li>Text generation by LLMs is called Inference</li>
<li>LLM Inference is faster on GPUs compared to CPUs</li>
<li>Pretty common ‚ÄúLLM-GPU‚Äù is the NVIDIA A100</li>
</ul>
<h2 id="background-story">Background Story ‚öôÔ∏è</h2>
<ul>
<li>We @Comma Soft AG are developing LLM pipelines</li>
<li>Each use case has different requirements</li>
<li>Sometimes Inference Speed is more important</li>
<li>More Hardware performance can/should improve Inference speed</li>
<li>To check out how much you can improve with more hardware, you can look into the scaling effect to see the trade-off between Inference speed and hardware costs</li>
</ul>
<h2 id="weird-finding">Weird Finding ü§î</h2>
<ul>
<li>NVIDIA released a benchmark (link see below)</li>
<li>It compares different GPU setups: 1, 2, 4, 8 GPUs for a common open-source model inference</li>
<li>It states that when you increase from 2 GPUs to 4 GPUs you get half the throughput; from 10 sentences/sec to 4.8 sentences/sec for LLAMA-2 13B</li>
</ul>
<h2 id="my-take">My Take ü§ó</h2>
<ul>
<li>The NVIDIA Benchmark is broken or some hiccup with copy-paste of results</li>
<li>Sentences/sec is a strange measure. Why not tokens per second which is more stable</li>
<li>I found another strange issue with model sizes and performance on NVIDIA GPUs in this benchmark. see this link: <a href="https://rb.gy/5l8qqp">https://rb.gy/5l8qqp</a></li>
<li>It is a problem when you cannot trust benchmarks as this leads to reimplementing benchmarks or running them again which is a waste of resources and barely sustainable</li>
<li>Benchmarks should be available open source to understand the measures and issues</li>
</ul>
<h2 id="questions-abcd">Questions üî†</h2>
<ul>
<li>What do you think is the reason for this weird benchmark result?</li>
<li>Do you have an idea why they measure in sentences per second and not in tokens per second?</li>
<li>What are your preferred sources for benchmarks when it comes to Inference performance?</li>
<li>What do you do to improve inference speed?</li>
</ul>
<h2 id="links">Links üìñ</h2>
<ul>
<li>NVIDIA AI Multi GPU Inference Benchmark: <a href="https://lnkd.in/e2sUsi63">https://lnkd.in/e2sUsi63</a></li>
<li>LLAMA 13B faster than LLAMA 7B? <a href="https://rb.gy/5l8qqp">https://rb.gy/5l8qqp</a></li>
<li>Mistrust in LLM Benchmarks! <a href="https://rb.gy/juw4pg">https://rb.gy/juw4pg</a></li>
<li>Why do LLMs have sizes: 7B 13B, and 70B? <a href="https://rb.gy/zkpk5r">https://rb.gy/zkpk5r</a></li>
</ul>
<p>NVIDIA could you please fix it or comment on what was the issue/reason</p>
<p>For more content, brainstorming, and discussions, follow me or reach out to me ü•∞</p>
<p>#LostInGenai #artificialintelligence #selectllm</p>
<p><a href="https://www.linkedin.com/posts/carsten-draschner_%F0%9D%97%A1%F0%9D%97%A9%F0%9D%97%9C%F0%9D%97%97%F0%9D%97%9C%F0%9D%97%94-%F0%9D%97%95%F0%9D%97%B2%F0%9D%97%BB%F0%9D%97%B0%F0%9D%97%B5%F0%9D%97%BA%F0%9D%97%AE%F0%9D%97%BF%F0%9D%97%B8-%F0%9D%97%BA%F0%9D%97%B6%F0%9D%97%B4%F0%9D%97%B5%F0%9D%98%81-activity-7176105937240231936-KzN2?utm_source=share&amp;utm_medium=member_desktop">LinkedIn Post</a></p>

<ul class="links-nextprev"><li class="links-nextprev-prev">‚Üê Previous<br> <a href="/blog/240709_too_many_llms_how_to_keep_track_with_all/">Too many LLMs?! How to keep track with all the Open Source Models? Identify the finetuned-masked LLMs and its position within the GenAI landscape!</a></li><li class="links-nextprev-next">Next ‚Üí<br><a href="/blog/240711_what_is_your_preferred_llm_family/">What is your preferred LLM family? And do you start with an already finetuned LLM? Why you have chosen this LLM? I love to hear your perspective!</a></li>
</ul>

			</heading-anchors>
		</main>

		<footer>
			<p>&copy; 2024 Carsten Felix Draschner, PhD</p>
		</footer>

		<!-- This page `/blog/240710_nvidia_benchmark_might_be_wrong/` was built on 2024-11-27T15:39:14.472Z -->
		<script type="module" src="/dist/rJ3_G-2ArF.js"></script>
	</body>
</html>
