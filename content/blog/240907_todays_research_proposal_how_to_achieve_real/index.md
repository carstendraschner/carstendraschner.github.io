---
title: Today's Research Proposal - How to achieve "real" thinking and reasoning in GenAI, rather than just relying on a silent Chain of Thought, as seen in ReflectionAI or possibly GPT-o1?
date: 2024-09-30
linkedInUrl: https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-sustainability-activity-7243978164564111361-12R6?utm_source=share&utm_medium=member_desktop
tags: blog
---

Exploring the potential for achieving true reasoning and thinking in Generative AI models beyond the current Chain of Thought methodologies.

![Image 1](/img/blog_images/1726499742573.jpeg)

**TL;DR ‚è±Ô∏è**
- Current state of reasoning in models
- Possibilities for transformers to learn to think
- Customization ideas for achieving true reasoning
- Open questions and discussion points

<!-- excerpt -->

## Currently, reasoning more through silent the CoT üò•

- There are currently models that claim to possess reasoning capabilities.
- However, this is more about the Chain of Thought and the use of special tokens.
- These enable the model to generate more text, thereby increasing the stability of its answers.
- This process of "reasoning" is not transparently/barely shown.
- I believe this is less about reasoning or thinking and more about statistical stability.
- Moreover, it is not possible to observe the reasoning process, and it is often difficult to identify when a model has gone astray.

## How could transformers learn to think? ü§Ø

- Why can I still imagine that it is possible to learn to think or reason with the transformer architecture?
- Due to the transformer architecture, which includes tokenization, attention, and multi-layer perceptron elements, as well as the universal function approximation hypothesis, the following can be imagined:
    1. In early layers, the network learns something akin to named entity recognition.
    2. Later layers and embedding dimensions create structures that learn propositional logic and structures similar to knowledge graphs or their embeddings.
    3. Finally, based on this, resonating and reflecting completeness of output logic components could be achieved.

## What else would I customize? üë®üèº‚Äçüíª (IMHO)

I would find it interesting to combine this with thought-diffusion models, making hierarchical planning possible. I have several more ideas..., reach out to me if you like to start a discussion ‚ù§Ô∏è

## Questions:

Are you aware of any approaches or research projects that attempt this?
What are your thoughts on that, how would you build "AGI" it?

I had great idea exchanges on this with colleagues from Comma Soft AG, Lamarr-Institut & Smart Data Analytics.

Let's not waste money and time on believing in marketing claims and rebranding of the word "reasoning", but let's start to think of how it could actually be achieved ü§ó

#AGI #GenAI #artificialintelligence #research

[LinkedIn Post](https://www.linkedin.com/posts/carsten-draschner_artificialintelligence-genai-sustainability-activity-7243978164564111361-12R6?utm_source=share&utm_medium=member_desktop)
