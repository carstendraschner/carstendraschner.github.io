---
title: New DE/EU Open Source LLM 🇪🇺 Teuken 7B, Now Truly Open Source?
date: 2024-09-30
linkedInUrl: https://www.linkedin.com/in/carsten-draschner/recent-activity/all/
tags: blog
---

New Model out of Open-GPT-X developed within Germany from European Perspective

![Image 1](/img/blog_images/1732616196378.jpeg)

**TL;DR ⏱️**
- New German OS LLM
- 7B, Transperant Docs
- Problems in Alignment?

<!-- excerpt -->

## Short Facts
🇪🇺 European language focus
🤖 7B parameters
🔗 Very open Apache 2.0 license
🛠️ Instruction Fine-tuned
📊 Not outperforming in Benchmarks but also within normal distribution (for 🇬🇧)
👶🏼 4k max context
💣 (EDIT) Alignment Discussion see here: [https://lnkd.in/eseXDMMS](https://lnkd.in/eseXDMMS)

My former colleagues Mehdi Ali (roommate within our time in Smart Data Analytics at Rheinische Friedrich-Wilhelms-Universität Bonn of Jens Lehmann) and Stefan Wrobel (one of my Ph.D. supervisors Rheinische Friedrich-Wilhelms-Universität Bonn) and their teams have released an LLM developed in Europe within OpenGPT-X & Fraunhofer IAIS. This has been developed with a focus on European languages. I'm excited to try it out right away and see the actual performance! They announced their own Leaderboard and the Model in somewhere in between other models of same size: [https://lnkd.in/eTgv8bjV](https://lnkd.in/eTgv8bjV)

## My Take 🤗

- I have high hopes for a better documentation of the development process and I am curious if this model can be called truly open source and not just open weight.
- I look forward to further European and German initiatives that also pursue (Gen)AI development here in 🇪🇺❤️

## My Questions (at Mehdi Ali, Michael Fromm, Max Lübbering, PhD and all your contributors):

- Is anyone capable to entirely reproduce the model from the documentation?
- What do you expect from Arena Elo Scores? 
- In which tasks would you recommend usage of your model over other models from Mistral AI, Meta, Google, Microsoft, Alibaba Cloud like Mistral7B, LLama3.18B, Gemma, Phi, Qwen...
- Will we see truly big LLMs in size of 50-400B Parameter that can compete with current top notch LLMs from your side?

We at Comma Soft AG provide with Alan.de a European and German Solution to use GenAI in a highly performant, safe and trusted environment. If you like to see more of our recent R&D, check my recent posts and reach out to me for more idea exchange 😊
