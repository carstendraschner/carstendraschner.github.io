---
title: New DE/EU Open Source LLM ğŸ‡ªğŸ‡º Teuken 7B, Now Truly Open Source?
date: 2024-09-30
linkedInUrl: https://www.linkedin.com/in/carsten-draschner/recent-activity/all/
tags: blog
---

New Model out of Open-GPT-X developed within Germany from European Perspective

![Image 1](/img/blog_images/1732616196378.jpeg)

**TL;DR â±ï¸**
- New German OS LLM
- 7B, Transperant Docs
- Problems in Alignment?

<!-- excerpt -->

## Short Facts
ğŸ‡ªğŸ‡º European language focus
ğŸ¤– 7B parameters
ğŸ”— Very open Apache 2.0 license
ğŸ› ï¸ Instruction Fine-tuned
ğŸ“Š Not outperforming in Benchmarks but also within normal distribution (for ğŸ‡¬ğŸ‡§)
ğŸ‘¶ğŸ¼ 4k max context
ğŸ’£ (EDIT) Alignment Discussion see here: [https://lnkd.in/eseXDMMS](https://lnkd.in/eseXDMMS)

My former colleagues Mehdi Ali (roommate within our time in Smart Data Analytics at Rheinische Friedrich-Wilhelms-UniversitÃ¤t Bonn of Jens Lehmann) and Stefan Wrobel (one of my Ph.D. supervisors Rheinische Friedrich-Wilhelms-UniversitÃ¤t Bonn) and their teams have released an LLM developed in Europe within OpenGPT-X & Fraunhofer IAIS. This has been developed with a focus on European languages. I'm excited to try it out right away and see the actual performance! They announced their own Leaderboard and the Model in somewhere in between other models of same size: [https://lnkd.in/eTgv8bjV](https://lnkd.in/eTgv8bjV)

## My Take ğŸ¤—

- I have high hopes for a better documentation of the development process and I am curious if this model can be called truly open source and not just open weight.
- I look forward to further European and German initiatives that also pursue (Gen)AI development here in ğŸ‡ªğŸ‡ºâ¤ï¸

## My Questions (at Mehdi Ali, Michael Fromm, Max LÃ¼bbering, PhD and all your contributors):

- Is anyone capable to entirely reproduce the model from the documentation?
- What do you expect from Arena Elo Scores? 
- In which tasks would you recommend usage of your model over other models from Mistral AI, Meta, Google, Microsoft, Alibaba Cloud like Mistral7B, LLama3.18B, Gemma, Phi, Qwen...
- Will we see truly big LLMs in size of 50-400B Parameter that can compete with current top notch LLMs from your side?

We at Comma Soft AG provide with Alan.de a European and German Solution to use GenAI in a highly performant, safe and trusted environment. If you like to see more of our recent R&D, check my recent posts and reach out to me for more idea exchange ğŸ˜Š
